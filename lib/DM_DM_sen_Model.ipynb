{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5c2a4d",
   "metadata": {},
   "source": [
    "# DM/DM_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b0e20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.optimize as optim\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction\n",
    "from __future__ import division\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from random import seed, shuffle\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import numpy.core.multiarray\n",
    "import cvxpy as cvx\n",
    "import dccp\n",
    "from dccp.problem import is_dccp\n",
    "import utils as ut\n",
    "import traceback\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0add3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4c11901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dbf0c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007cc6ef",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7fbd27",
   "metadata": {},
   "source": [
    "https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d867a",
   "metadata": {},
   "source": [
    "**We filtered the data based on criterion provided in \n",
    "<br>https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb**\n",
    "\n",
    "\"If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "<br>We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "<br>In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "<br>We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "581871b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df[\"days_b_screening_arrest\"]<=30) & (df[\"days_b_screening_arrest\"]>=-30)]\n",
    "df = df.loc[df[\"is_recid\"] != -1]\n",
    "df = df.loc[df[\"c_charge_degree\"] != \"O\"]\n",
    "df = df.loc[(df[\"race\"] == \"African-American\") | (df[\"race\"] == \"Caucasian\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "236a5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set two_year_recid as y convert the negative label from 0 to -1 for classifiers\n",
    "y = df['two_year_recid'].to_numpy()\n",
    "y[y==0] = -1\n",
    "len_rows = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bccfc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"race\", \"sex\", \"age_cat\", \"c_charge_degree\", \"priors_count\", \"juv_fel_count\"] # all features\n",
    "cont_features = [\"priors_count\", \"juv_fel_count\"] # continuous features \n",
    "sensitive_attrs = [\"race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9eab6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control = np.array([]).reshape(len_rows,0)\n",
    "X = np.array([]).reshape(len_rows, 0) \n",
    "feature_names = []\n",
    "\n",
    "for feature in features:\n",
    "    vals = df[feature]\n",
    "    if feature in cont_features:\n",
    "        # normalize\n",
    "        vals = preprocessing.scale(vals)\n",
    "        # convert to 2d array\n",
    "        vals  = np.reshape(vals, (len_rows, -1))\n",
    "    else:\n",
    "        # use binary labels\n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        lb.fit(vals)\n",
    "        vals = lb.transform(vals)\n",
    "    \n",
    "    if feature in sensitive_attr:\n",
    "        X_control = np.hstack((X_control, vals))\n",
    "    \n",
    "    X = np.hstack((X, vals))\n",
    "    if vals.shape[1] == 1:\n",
    "        feature_names.append(feature)\n",
    "    else:\n",
    "        for c in lb.classes_:\n",
    "            feature_names.append(f\"{feature}_{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7fc05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add intercept to data\n",
    "m,n = X.shape\n",
    "intercept = np.ones(m).reshape(m, 1)\n",
    "X = np.concatenate((intercept,X), axis = 1)\n",
    "\n",
    "feature_names = [\"intercept\"] + feature_names\n",
    "assert(len(feature_names) == X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54cda0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_train_test(x_all, y_all, x_control_all, train_fold_size):\n",
    "    \n",
    "    split_point = int(round(float(x_all.shape[0]) * train_fold_size))\n",
    "    x_all_train = x_all[:split_point]\n",
    "    x_all_test = x_all[split_point:]\n",
    "    y_all_train = y_all[:split_point]\n",
    "    y_all_test = y_all[split_point:]\n",
    "    x_control_all_train = {}\n",
    "    x_control_all_test = {}\n",
    "    #for k in x_control_all.keys():\n",
    "    x_control_all_train = x_control_all[:split_point]\n",
    "    x_control_all_test = x_control_all[split_point:]\n",
    "    normalizer = preprocessing.Normalizer()\n",
    "    x_all_train = normalizer.fit_transform(x_all_train)\n",
    "\n",
    "    return x_all_train, y_all_train, {\"race\": x_control_all_train.flatten()}, x_all_test, y_all_test, {\"race\":x_control_all_test.flatten()}\n",
    "\n",
    "train_fold_size = 0.5\n",
    "X_train, y_train, X_control_train, X_test, y_test, X_control_test = split_into_train_test(X, y, X_control, train_fold_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450555a",
   "metadata": {},
   "source": [
    "# Objective functions with constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b63bb",
   "metadata": {},
   "source": [
    "The following formulas are summarized in paper https://arxiv.org/abs/1610.08452.\n",
    "<br>In this section, we implement methods provided in the paper's author's github repo https://github.com/mbilalzafar/fair-classification/blob/master/fair_classification/utils.py that use OMR, FPR, FNR, and both FNR and FPR as constraints in our logistic regressions and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312972ee",
   "metadata": {},
   "source": [
    "<img src='../figs/dm_notions.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93ff778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_disp_mist(X, y, X_control, loss_function, EPS, cons_params):\n",
    "\n",
    "    # cons_type, sensitive_attrs_to_cov_thresh, take_initial_sol, gamma, tau, mu, EPS, cons_type\n",
    "    \"\"\"\n",
    "    Function that trains the model subject to various fairness constraints.\n",
    "    If no constraints are given, then simply trains an unaltered classifier.\n",
    "    Example usage in: \"disparate_mistreatment/synthetic_data_demo/decision_boundary_demo.py\"\n",
    "    ----\n",
    "    Inputs:\n",
    "    X: (n) x (d+1) numpy array -- n = number of examples, d = number of features, one feature is the intercept\n",
    "    y: 1-d numpy array (n entries)\n",
    "    x_control: dictionary of the type {\"s\": [...]}, key \"s\" is the sensitive feature name, and the value is a 1-d list with n elements holding the sensitive feature values\n",
    "    loss_function: the loss function that we want to optimize -- for now we have implementation of logistic loss, but other functions like hinge loss can also be added\n",
    "    EPS: stopping criteria for the convex solver. check the CVXPY documentation for details. default for CVXPY is 1e-6\n",
    "    cons_params: is None when we do not want to apply any constraints\n",
    "    otherwise: cons_params is a dict with keys as follows:\n",
    "        - cons_type: \n",
    "            - 0 for all misclassifications \n",
    "            - 1 for FPR\n",
    "            - 2 for FNR\n",
    "            - 4 for both FPR and FNR\n",
    "        - tau: DCCP parameter, controls how much weight to put on the constraints, if the constraints are not satisfied, then increase tau -- default is DCCP val 0.005\n",
    "        - mu: DCCP parameter, controls the multiplicative factor by which the tau increases in each DCCP iteration -- default is the DCCP val 1.2\n",
    "        - take_initial_sol: whether the starting point for DCCP should be the solution for the original (unconstrained) classifier -- default value is True\n",
    "        - sensitive_attrs_to_cov_thresh: covariance threshold for each cons_type, eg, key 1 contains the FPR covariance\n",
    "    ----\n",
    "    Outputs:\n",
    "    w: the learned weight vector for the classifier\n",
    "    \"\"\"\n",
    "\n",
    "    max_iters = 100 # for the convex program\n",
    "    max_iter_dccp = 50  # for the dccp algo\n",
    "\n",
    "    \n",
    "    num_points, num_features = X.shape\n",
    "    w = cvx.Variable(num_features) # this is the weight vector\n",
    "\n",
    "    # initialize a random value of w\n",
    "    np.random.seed(5243)\n",
    "    w.value = np.random.rand(X.shape[1])\n",
    "\n",
    "    if cons_params is None: # just train a simple classifier, no fairness constraints\n",
    "        constraints = []\n",
    "    else:\n",
    "        constraints = get_constraint_list_cov(X, y, X_control, cons_params[\"sensitive_attrs_to_cov_thresh\"], cons_params[\"cons_type\"], w)\n",
    "\n",
    "\n",
    "    if loss_function == \"logreg\":\n",
    "        # constructing the logistic loss problem\n",
    "        loss = cvx.sum( cvx.logistic( cvx.multiply(-y, X*w) )  ) / num_points # we are converting y to a diagonal matrix for consistent\n",
    "        #loss = cvx.sum(cvx.multiply(y, x*w) - cvx.logistic(x*w))\n",
    "    elif loss_function == \"svm\":\n",
    "        loss = cvx.sum( cvx.pos(1 - cvx.multiply(y, X*w))) / num_points\n",
    "        \n",
    "    # sometimes, its a good idea to give a starting point to the constrained solver\n",
    "    # this starting point for us is the solution to the unconstrained optimization problem\n",
    "    # another option of starting point could be any feasible solution\n",
    "    if cons_params is not None:\n",
    "        if cons_params.get(\"take_initial_sol\") is None: # true by default\n",
    "            take_initial_sol = True\n",
    "        elif cons_params[\"take_initial_sol\"] == False:\n",
    "            take_initial_sol = False\n",
    "\n",
    "        if take_initial_sol == True: # get the initial solution\n",
    "            p = cvx.Problem(cvx.Minimize(loss), [])\n",
    "            p.solve()\n",
    "\n",
    "\n",
    "    # construct the cvxpy problem\n",
    "    prob = cvx.Problem(cvx.Minimize(loss), constraints)\n",
    "\n",
    "    # print \"\\n\\n\"\n",
    "    # print \"Problem is DCP (disciplined convex program):\", prob.is_dcp()\n",
    "    # print \"Problem is DCCP (disciplined convex-concave program):\", is_dccp(prob)\n",
    "\n",
    "    try:\n",
    "\n",
    "        tau, mu = 0.005, 1.2 # default dccp parameters, need to be varied per dataset\n",
    "        if cons_params is not None: # in case we passed these parameters as a part of dccp constraints\n",
    "            if cons_params.get(\"tau\") is not None: tau = cons_params[\"tau\"]\n",
    "            if cons_params.get(\"mu\") is not None: mu = cons_params[\"mu\"]\n",
    "\n",
    "        prob.solve(method='dccp', tau=tau, mu=mu, tau_max=1e10,\n",
    "            solver='ECOS', verbose=False, \n",
    "            feastol=EPS, abstol=EPS, reltol=EPS,feastol_inacc=EPS, abstol_inacc=EPS, reltol_inacc=EPS,\n",
    "            max_iters=max_iters, max_iter=max_iter_dccp)\n",
    "\n",
    "        \n",
    "        assert(prob.status == \"Converged\" or prob.status == \"optimal\")\n",
    "        # print \"Optimization done, problem status:\", prob.status\n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    # check that the fairness constraint is satisfied\n",
    "    for f_c in constraints:\n",
    "       # assert(f_c.value == True) # can comment this out if the solver fails too often, but make sure that the constraints are satisfied empirically. alternatively, consider increasing tau parameter\n",
    "        pass\n",
    "        \n",
    "\n",
    "    w = np.array(w.value).flatten() # flatten converts it to a 1d array\n",
    "\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb797284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraint_list_cov(X_train, y_train, X_control_train, sensitive_attrs_to_cov_thresh, cons_type, w):\n",
    "\n",
    "    \"\"\"\n",
    "    get the list of constraints to be fed to the minimizer\n",
    "    cons_type == 0: means the whole combined misclassification constraint (without FNR or FPR)\n",
    "    cons_type == 1: FPR constraint\n",
    "    cons_type == 2: FNR constraint\n",
    "    cons_type == 4: both FPR as well as FNR constraints\n",
    "    sensitive_attrs_to_cov_thresh: is a dict like {s: {cov_type: val}}\n",
    "    s is the sensitive attr\n",
    "    cov_type is the covariance type. contains the covariance for all misclassifications, FPR and for FNR etc\n",
    "    \"\"\"\n",
    "\n",
    "    constraints = []\n",
    "    for attr in sensitive_attrs_to_cov_thresh.keys():\n",
    "        attr_arr = X_control_train[attr]\n",
    "        #attr_arr_transformed, index_dict = get_one_hot_encoding(attr_arr)\n",
    "        index_dict = None        \n",
    "        if index_dict is None: # binary attribute, in this case, the attr_arr_transformed is the same as the attr_arr\n",
    "\n",
    "            s_val_to_total = {ct:{} for ct in [0,1,2]} # constrain type -> sens_attr_val -> total number\n",
    "            s_val_to_avg = {ct:{} for ct in [0,1,2]}\n",
    "            cons_sum_dict = {ct:{} for ct in [0,1,2]} # sum of entities (females and males) in constraints are stored here\n",
    "\n",
    "            for v in set(attr_arr):\n",
    "                s_val_to_total[0][v] = sum(X_control_train[attr] == v)\n",
    "                s_val_to_total[1][v] = sum(np.logical_and(X_control_train[attr] == v, y_train == -1)) # FPR constraint so we only consider the ground truth negative dataset for computing the covariance\n",
    "                s_val_to_total[2][v] = sum(np.logical_and(X_control_train[attr] == v, y_train == +1))\n",
    "\n",
    "\n",
    "            for ct in [0,1,2]:\n",
    "                s_val_to_avg[ct][0] = s_val_to_total[ct][1] / float(s_val_to_total[ct][0] + s_val_to_total[ct][1]) # N1/N in our formulation, differs from one constraint type to another\n",
    "                s_val_to_avg[ct][1] = 1.0 - s_val_to_avg[ct][0] # N0/N\n",
    "\n",
    "            \n",
    "            for v in set(attr_arr):\n",
    "\n",
    "                idx = X_control_train[attr] == v                \n",
    "\n",
    "\n",
    "                #################################################################\n",
    "                # #DCCP constraints\n",
    "                dist_bound_prod = cvx.multiply(y_train[idx], X_train[idx] * w) # y.f(x)\n",
    "                \n",
    "                cons_sum_dict[0][v] = cvx.sum( cvx.minimum(0, dist_bound_prod) ) * (s_val_to_avg[0][v] / len(X_train)) # avg misclassification distance from boundary\n",
    "                cons_sum_dict[1][v] = cvx.sum( cvx.minimum(0, cvx.multiply( (1 - y_train[idx])/2.0, dist_bound_prod) ) ) * (s_val_to_avg[1][v] / sum(y_train == -1)) # avg false positive distance from boundary (only operates on the ground truth neg dataset)\n",
    "                cons_sum_dict[2][v] = cvx.sum( cvx.minimum(0, cvx.multiply( (1 + y_train[idx])/2.0, dist_bound_prod) ) ) * (s_val_to_avg[2][v] / sum(y_train == +1)) # avg false negative distance from boundary\n",
    "                #################################################################\n",
    "\n",
    "                \n",
    "            if cons_type == 4:\n",
    "                cts = [1,2]\n",
    "            elif cons_type in [0,1,2]:\n",
    "                cts = [cons_type]\n",
    "            \n",
    "            else:\n",
    "                raise Exception(\"Invalid constraint type\")\n",
    "\n",
    "\n",
    "            #################################################################\n",
    "            #DCCP constraints\n",
    "            for ct in cts:\n",
    "                thresh = abs(sensitive_attrs_to_cov_thresh[attr][ct][1] - sensitive_attrs_to_cov_thresh[attr][ct][0])\n",
    "                constraints.append( cons_sum_dict[ct][1] <= cons_sum_dict[ct][0]  + thresh )\n",
    "                constraints.append( cons_sum_dict[ct][1] >= cons_sum_dict[ct][0]  - thresh )\n",
    "\n",
    "            #################################################################\n",
    "\n",
    "\n",
    "            \n",
    "        else: # otherwise, its a categorical attribute, so we need to set the cov thresh for each value separately\n",
    "            # need to fill up this part\n",
    "            raise Exception(\"Fill the constraint code for categorical sensitive features... Exiting...\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6111ac",
   "metadata": {},
   "source": [
    "# Methods for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25c2f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy_1():\n",
    "    d0 = y-predicted_labels\n",
    "    d1 = d0[d0 != 0]\n",
    "    all_pro = len(d1)/len(y)\n",
    "    # FPR y = -1, prediction = 1\n",
    "    d2 = d0[d0 == -2]\n",
    "    y2 = y[y == -1]\n",
    "    fpr_pro = len(d2)/len(y2)\n",
    "    # FNR y = 1, prediction = -1\n",
    "    d3 = d0[d0 == 2]\n",
    "    y3 = y[y == 1]\n",
    "    fnr_pro = len(d3)/len(y3)\n",
    "    print(\"ALL:\"+str(all_pro),\"FPR:\"+str(fpr_pro),\"FNR:\"+str(fnr_pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "def02bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fpr_fnr_sensitive_features(y_true, y_pred, x_control, sensitive_attrs, verbose = False):\n",
    "\n",
    "\n",
    "\n",
    "    # we will make some changes to x_control in this function, so make a copy in order to preserve the origianl referenced object\n",
    "    x_control_internal = deepcopy(x_control)\n",
    "\n",
    "    s_attr_to_fp_fn = {}\n",
    "    \n",
    "    for s in sensitive_attrs:\n",
    "        s_attr_to_fp_fn[s] = {}\n",
    "        s_attr_vals = x_control_internal[s]\n",
    "        if verbose == True:\n",
    "            print( \"||  s  || FPR. || FNR. ||\")\n",
    "        for s_val in sorted(list(set(s_attr_vals))):\n",
    "            s_attr_to_fp_fn[s][s_val] = {}\n",
    "            y_true_local = y_true[s_attr_vals==s_val]\n",
    "            y_pred_local = y_pred[s_attr_vals==s_val]\n",
    "\n",
    "            \n",
    "\n",
    "            acc = float(sum(y_true_local==y_pred_local)) / len(y_true_local)\n",
    "\n",
    "            fp = sum(np.logical_and(y_true_local == -1.0, y_pred_local == +1.0)) # something which is -ve but is misclassified as +ve\n",
    "            fn = sum(np.logical_and(y_true_local == +1.0, y_pred_local == -1.0)) # something which is +ve but is misclassified as -ve\n",
    "            tp = sum(np.logical_and(y_true_local == +1.0, y_pred_local == +1.0)) # something which is +ve AND is correctly classified as +ve\n",
    "            tn = sum(np.logical_and(y_true_local == -1.0, y_pred_local == -1.0)) # something which is -ve AND is correctly classified as -ve\n",
    "\n",
    "            all_neg = sum(y_true_local == -1.0)\n",
    "            all_pos = sum(y_true_local == +1.0)\n",
    "\n",
    "            fpr = float(fp) / float(fp + tn)\n",
    "            fnr = float(fn) / float(fn + tp)\n",
    "            tpr = float(tp) / float(tp + fn)\n",
    "            tnr = float(tn) / float(tn + fp)\n",
    "\n",
    "\n",
    "            s_attr_to_fp_fn[s][s_val][\"fp\"] = fp\n",
    "            s_attr_to_fp_fn[s][s_val][\"fn\"] = fn\n",
    "            s_attr_to_fp_fn[s][s_val][\"fpr\"] = fpr\n",
    "            s_attr_to_fp_fn[s][s_val][\"fnr\"] = fnr\n",
    "\n",
    "            s_attr_to_fp_fn[s][s_val][\"acc\"] = (tp + tn) / (tp + tn + fp + fn)\n",
    "            if verbose == True:\n",
    "                if isinstance(s_val, float): # print the int value of the sensitive attr val\n",
    "                    s_val = int(s_val)\n",
    "                print (\"||  %s  || %0.2f || %0.2f ||\" % (s_val, fpr, fnr))\n",
    "\n",
    "        \n",
    "        return s_attr_to_fp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48a9960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensitive_attr_constraint_fpr_fnr_cov(model, X_arr, y_arr_true, y_arr_dist_boundary, X_control_arr, verbose=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we compute the covariance between sensitive attr val and ONLY misclassification distances from boundary for False-positives\n",
    "    (-N_1 / N) sum_0(min(0, y.f(x))) + (N_0 / N) sum_1(min(0, y.f(x))) for all misclassifications\n",
    "    (-N_1 / N) sum_0(min(0, (1-y)/2 . y.f(x))) + (N_0 / N) sum_1(min(0,  (1-y)/2. y.f(x))) for FPR\n",
    "    y_arr_true are the true class labels\n",
    "    y_arr_dist_boundary are the predicted distances from the decision boundary\n",
    "    If the model is None, we assume that the y_arr_dist_boundary contains the distace from the decision boundary\n",
    "    If the model is not None, we just compute a dot product or model and x_arr\n",
    "    for the case of SVM, we pass the distace from bounday becase the intercept in internalized for the class\n",
    "    and we have compute the distance using the project function\n",
    "    this function will return -1 if the constraint specified by thresh parameter is not satifsified\n",
    "    otherwise it will reutrn +1\n",
    "    if the return value is >=0, then the constraint is satisfied\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    assert(X_arr.shape[0] == X_control_arr.shape[0])\n",
    "    if len(X_control_arr.shape) > 1: # make sure we just have one column in the array\n",
    "        assert(X_control_arr.shape[1] == 1)\n",
    "    if len(set(X_control_arr)) != 2: # non binary attr\n",
    "        raise Exception(\"Non binary attr, fix to handle non bin attrs\")\n",
    "\n",
    "    \n",
    "    arr = []\n",
    "    if model is None:\n",
    "        arr = y_arr_dist_boundary * y_arr_true # simply the output labels\n",
    "    else:\n",
    "        arr = np.dot(model, X_arr.T) * y_arr_true # the product with the weight vector -- the sign of this is the output label\n",
    "    arr = np.array(arr)\n",
    "\n",
    "    s_val_to_total = {ct:{} for ct in [0,1,2]}\n",
    "    s_val_to_avg = {ct:{} for ct in [0,1,2]}\n",
    "    cons_sum_dict = {ct:{} for ct in [0,1,2]} # sum of entities (females and males) in constraints are stored here\n",
    "\n",
    "    for v in set(X_control_arr):\n",
    "        s_val_to_total[0][v] = sum(X_control_arr == v)\n",
    "        s_val_to_total[1][v] = sum(np.logical_and(X_control_arr == v, y_arr_true == -1))\n",
    "        s_val_to_total[2][v] = sum(np.logical_and(X_control_arr == v, y_arr_true == +1))\n",
    "\n",
    "\n",
    "    for ct in [0,1,2]:\n",
    "        s_val_to_avg[ct][0] = s_val_to_total[ct][1] / float(s_val_to_total[ct][0] + s_val_to_total[ct][1]) # N1 / N\n",
    "        s_val_to_avg[ct][1] = 1.0 - s_val_to_avg[ct][0] # N0 / N\n",
    "\n",
    "    \n",
    "    for v in set(X_control_arr):\n",
    "        idx = X_control_arr == v\n",
    "        dist_bound_prod = arr[idx]\n",
    "\n",
    "        cons_sum_dict[0][v] = sum( np.minimum(0, dist_bound_prod) ) * (s_val_to_avg[0][v] / len(X_arr))\n",
    "        cons_sum_dict[1][v] = sum( np.minimum(0, ( (1 - y_arr_true[idx]) / 2 ) * dist_bound_prod) ) * (s_val_to_avg[1][v] / sum(y_arr_true == -1))\n",
    "        cons_sum_dict[2][v] = sum( np.minimum(0, ( (1 + y_arr_true[idx]) / 2 ) * dist_bound_prod) ) * (s_val_to_avg[2][v] / sum(y_arr_true == +1))\n",
    "        \n",
    "\n",
    "    cons_type_to_name = {0:\"ALL\", 1:\"FPR\", 2:\"FNR\"}\n",
    "    for cons_type in [0,1,2]:\n",
    "        cov_type_name = cons_type_to_name[cons_type]    \n",
    "        cov = cons_sum_dict[cons_type][1] - cons_sum_dict[cons_type][0]\n",
    "        if verbose == True:\n",
    "            print( \"Covariance for type '%s' is: %0.7f\" %(cov_type_name, cov))\n",
    "        \n",
    "    return cons_sum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "321e3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, X_train, y_train, X_test, y_test, y_train_predicted, y_test_predicted):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    returns the train/test accuracy of the model\n",
    "    we either pass the model (w)\n",
    "    else we pass y_predicted\n",
    "    \"\"\"\n",
    "    if model is not None and y_test_predicted is not None:\n",
    "        print (\"Either the model (w) or the predicted labels should be None\")\n",
    "        raise Exception(\"Either the model (w) or the predicted labels should be None\")\n",
    "\n",
    "    if model is not None:\n",
    "        y_test_predicted = np.sign(np.dot(X_test, model))\n",
    "        y_train_predicted = np.sign(np.dot(X_train, model))\n",
    "\n",
    "    def get_accuracy(y, Y_predicted):\n",
    "        correct_answers = (Y_predicted == y).astype(int) # will have 1 when the prediction and the actual label match\n",
    "        accuracy = float(sum(correct_answers)) / float(len(correct_answers))\n",
    "        return accuracy, sum(correct_answers)\n",
    "\n",
    "    train_score, correct_answers_train = get_accuracy(y_train, y_train_predicted)\n",
    "    test_score, correct_answers_test = get_accuracy(y_test, y_test_predicted)\n",
    "\n",
    "    return train_score, test_score, correct_answers_train, correct_answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49414a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_boundary(w, X, s_attr_arr):\n",
    "\n",
    "    \"\"\"\n",
    "        if we have boundaries per group, then use those separate boundaries for each sensitive group\n",
    "        else, use the same weight vector for everything\n",
    "    \"\"\"\n",
    "\n",
    "    distances_boundary = np.zeros(X.shape[0])\n",
    "    if isinstance(w, dict): # if we have separate weight vectors per group\n",
    "        for k in w.keys(): # for each w corresponding to each sensitive group\n",
    "            d = np.dot(X, w[k])\n",
    "            distances_boundary[s_attr_arr == k] = d[s_attr_arr == k] # set this distance only for people with this sensitive attr val\n",
    "    else: # we just learn one w for everyone else\n",
    "        distances_boundary = np.dot(X, w)\n",
    "    return distances_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e8a2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_stats(w, X_train, y_train, X_control_train, X_test, y_test, x_control_test, sensitive_attrs):\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    assert(len(sensitive_attrs) == 1) # ensure that we have just one sensitive attribute\n",
    "    s_attr = \"race\" # for now, lets compute the accuracy for just one sensitive attr\n",
    "    #s_attr = sensitive_attrs[0] # for now, lets compute the accuracy for just one sensitive attr\n",
    "\n",
    "\n",
    "    # compute distance from boundary\n",
    "    distances_boundary_train = get_distance_boundary(w, X_train, X_control_train[s_attr])\n",
    "    distances_boundary_test = get_distance_boundary(w, X_test, X_control_test[s_attr])\n",
    "\n",
    "    # compute the class labels\n",
    "    all_class_labels_assigned_train = np.sign(distances_boundary_train)\n",
    "    all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "\n",
    "\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = check_accuracy(None, X_train, y_train, X_test, y_test, all_class_labels_assigned_train, all_class_labels_assigned_test)\n",
    "\n",
    "    \n",
    "    cov_all_train = {}\n",
    "    cov_all_test = {}\n",
    "    for s_attr in sensitive_attrs:\n",
    "        \n",
    "        \n",
    "        print_stats = False # we arent printing the stats for the train set to avoid clutter\n",
    "\n",
    "        # uncomment these lines to print stats for the train fold\n",
    "        # print \"*** Train ***\"\n",
    "        # print \"Accuracy: %0.3f\" % (train_score)\n",
    "        # print_stats = True\n",
    "        s_attr_to_fp_fn_train = get_fpr_fnr_sensitive_features(y_train, all_class_labels_assigned_train, X_control_train, sensitive_attrs, print_stats)\n",
    "        cov_all_train[s_attr] = get_sensitive_attr_constraint_fpr_fnr_cov(None, X_train, y_train, distances_boundary_train, X_control_train[s_attr]) \n",
    "        \n",
    "\n",
    "        print (\"\\n\")\n",
    "        print( \"Accuracy: %0.3f\" % (test_score))\n",
    "        print_stats = True # only print stats for the test fold\n",
    "        s_attr_to_fp_fn_test = get_fpr_fnr_sensitive_features(y_test, all_class_labels_assigned_test, X_control_test, sensitive_attrs, print_stats)\n",
    "        cov_all_test[s_attr] = get_sensitive_attr_constraint_fpr_fnr_cov(None, X_test, y_test, distances_boundary_test, X_control_test[s_attr]) \n",
    "        print (\"\\n\")\n",
    "\n",
    "    return train_score, test_score, cov_all_train, cov_all_test, s_attr_to_fp_fn_train, s_attr_to_fp_fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03bbbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier():\n",
    "    w = train_model_disp_mist(X_train, y_train, X_control_train, loss_function, EPS, cons_params)\n",
    "\n",
    "    train_score, test_score, cov_all_train, cov_all_test, s_attr_to_fp_fn_train, s_attr_to_fp_fn_test = get_clf_stats(w, X_train, y_train, X_control_train, X_test, y_test, X_control_test, sensitive_attrs)\n",
    "\n",
    "    # accuracy and FPR are for the test because we need of for plotting\n",
    "    return w, test_score, s_attr_to_fp_fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "007277be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy_noConstraint():\n",
    "    \"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    cons_params['cons_type'] = 0 # FPR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    print(cons_params)\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier()\n",
    "    # print(\"\\n-----------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "749b2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy_FPR():\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    print(\"\\n\\n== Constraints on FPR ==\") # setting parameter for constraints\n",
    "    cons_params['cons_type'] = 1 # FPR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    print(cons_params)\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa8120f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy_FNR():\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    print(\"\\n\\n== Constraints on FNR ==\") # setting parameter for constraints\n",
    "    cons_params['cons_type'] = 2 # FNR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    print(cons_params)\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b9902c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_accuracy_allConstraints():\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    print(\"\\n\\n== Constraints on FNR and FPR ==\") # setting parameter for constraints\n",
    "    cons_params['cons_type'] = 4 # FNR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    print(cons_params)\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b1a25",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11948bff",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c976b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Unconstrained (original) classifier ==\n",
      "{'cons_type': 0, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.660\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.34 || 0.32 ||\n",
      "||  1  || 0.18 || 0.62 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "{'cons_type': 1, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.649\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.27 || 0.41 ||\n",
      "||  1  || 0.25 || 0.53 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "{'cons_type': 2, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.651\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.28 || 0.39 ||\n",
      "||  1  || 0.29 || 0.47 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR and FPR ==\n",
      "{'cons_type': 4, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.651\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.27 || 0.41 ||\n",
      "||  1  || 0.24 || 0.53 ||\n",
      "\n",
      "\n",
      "runtime of the complete DM model is 9.24 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "loss_function = \"logreg\" \n",
    "EPS = 1e-6\n",
    "cons_type = 0 # No constraint at very beginning \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "\n",
    "cons_params = None\n",
    "cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "start_dm = time.time()\n",
    "return_accuracy_noConstraint()\n",
    "return_accuracy_FPR()\n",
    "return_accuracy_FNR()\n",
    "return_accuracy_allConstraints()\n",
    "\n",
    "end_dm = time.time()\n",
    "runtime_dm = (end_dm-start_dm)\n",
    "print(f'runtime of the complete DM model is {np.round(runtime_dm, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec1107",
   "metadata": {},
   "source": [
    "## Support vector machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac65bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Unconstrained (original) classifier ==\n",
      "{'cons_type': 0, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.649\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.30 ||\n",
      "||  1  || 0.20 || 0.62 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "{'cons_type': 1, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.650\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.31 || 0.37 ||\n",
      "||  1  || 0.27 || 0.51 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "{'cons_type': 2, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.652\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.35 ||\n",
      "||  1  || 0.27 || 0.50 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR and FPR ==\n",
      "{'cons_type': 4, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.650\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.28 || 0.40 ||\n",
      "||  1  || 0.24 || 0.53 ||\n",
      "\n",
      "\n",
      "runtime of the complete DM model is 8.44 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "loss_function = \"svm\" \n",
    "EPS = 1e-6\n",
    "cons_type = 0 # No constraint at very beginning \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "\n",
    "cons_params = None\n",
    "cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "start_dm = time.time()\n",
    "return_accuracy_noConstraint()\n",
    "return_accuracy_FPR()\n",
    "return_accuracy_FNR()\n",
    "return_accuracy_allConstraints()\n",
    "\n",
    "end_dm = time.time()\n",
    "runtime_dm = (end_dm-start_dm)\n",
    "print(f'runtime of the complete DM model is {np.round(runtime_dm, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c56e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d15da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
