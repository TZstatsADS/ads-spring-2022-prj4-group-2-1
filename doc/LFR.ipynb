{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d960fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.optimize as optim\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e1ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/compas-scores-two-years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35151005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>...</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>High</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex          age_cat              race  juv_fel_count  decile_score  \\\n",
       "0  Male  Greater than 45             Other              0             1   \n",
       "1  Male          25 - 45  African-American              0             3   \n",
       "2  Male     Less than 25  African-American              0             4   \n",
       "3  Male     Less than 25  African-American              0             8   \n",
       "4  Male          25 - 45             Other              0             1   \n",
       "\n",
       "   juv_misd_count  juv_other_count  priors_count  days_b_screening_arrest  \\\n",
       "0               0                0             0                     -1.0   \n",
       "1               0                0             0                     -1.0   \n",
       "2               0                1             4                     -1.0   \n",
       "3               1                0             1                      NaN   \n",
       "4               0                0             2                      NaN   \n",
       "\n",
       "   c_days_from_compas  ... is_violent_recid  decile_score.1  score_text  \\\n",
       "0                 1.0  ...                0               1         Low   \n",
       "1                 1.0  ...                1               3         Low   \n",
       "2                 1.0  ...                0               4         Low   \n",
       "3                 1.0  ...                0               8        High   \n",
       "4                76.0  ...                0               1         Low   \n",
       "\n",
       "   v_decile_score v_score_text  priors_count.1 start   end  event  \\\n",
       "0               1          Low               0     0   327      0   \n",
       "1               1          Low               0     9   159      1   \n",
       "2               3          Low               4     0    63      0   \n",
       "3               6       Medium               1     0  1174      0   \n",
       "4               1          Low               2     0  1102      0   \n",
       "\n",
       "   two_year_recid  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unrelated columns\n",
    "df=df.drop(columns=['id', 'name', 'first', 'last',\n",
    "                    'compas_screening_date','dob','age','c_jail_in', \n",
    "                    'c_jail_out', 'c_case_number','c_offense_date','c_charge_desc', \n",
    "                    'c_arrest_date','r_charge_desc',\n",
    "                    'r_case_number','r_charge_desc','r_offense_date', \n",
    "                    'r_jail_in', 'r_jail_out','violent_recid','vr_case_number',\n",
    "                    'vr_offense_date', 'vr_charge_desc', 'screening_date',\n",
    "                    'v_screening_date','in_custody','out_custody','r_charge_degree',\n",
    "                    'r_days_from_arrest','vr_charge_degree','type_of_assessment',\n",
    "                    'v_type_of_assessment' ])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9deb71f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_days_from_compas', 'c_charge_degree',\n",
       "       'is_recid', 'is_violent_recid', 'decile_score.1', 'score_text',\n",
       "       'v_decile_score', 'v_score_text', 'priors_count.1', 'start', 'end',\n",
       "       'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e6c80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7214, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81f73a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5915, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only two races\n",
    "df = df[(df.race=='African-American') | (df.race=='Caucasian')]\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59453091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical: ['sex', 'age_cat', 'race', 'c_charge_degree', 'score_text', 'v_score_text']\n",
      "numerical: ['juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count', 'priors_count', 'days_b_screening_arrest', 'c_days_from_compas', 'is_recid', 'is_violent_recid', 'decile_score.1', 'v_decile_score', 'priors_count.1', 'start', 'end', 'event']\n"
     ]
    }
   ],
   "source": [
    "label_column = ['two_year_recid']\n",
    "catogory_features = []\n",
    "numeric_features = []\n",
    "\n",
    "for col in df.columns.values:\n",
    "    if col in label_column:\n",
    "        continue\n",
    "    elif df[col].dtypes in ('int64', 'float64') :\n",
    "        numeric_features += [col]\n",
    "    else:\n",
    "        catogory_features += [col]\n",
    "        \n",
    "print(\"categorical:\", catogory_features)\n",
    "print(\"numerical:\", numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ac76ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>...</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>428.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age_cat  race  juv_fel_count  decile_score  juv_misd_count  \\\n",
       "1    1        0     0              0             3               0   \n",
       "2    1        2     0              0             4               0   \n",
       "6    1        0     1              0             6               0   \n",
       "8    0        0     1              0             1               0   \n",
       "9    1        2     1              0             3               0   \n",
       "\n",
       "   juv_other_count  priors_count  days_b_screening_arrest  c_days_from_compas  \\\n",
       "1                0             0                     -1.0                 1.0   \n",
       "2                1             4                     -1.0                 1.0   \n",
       "6                0            14                     -1.0                 1.0   \n",
       "8                0             0                     -1.0                 1.0   \n",
       "9                0             1                    428.0               308.0   \n",
       "\n",
       "   ...  is_violent_recid  decile_score.1  score_text  v_decile_score  \\\n",
       "1  ...                 1               3           1               1   \n",
       "2  ...                 0               4           1               3   \n",
       "6  ...                 0               6           2               2   \n",
       "8  ...                 0               1           1               1   \n",
       "9  ...                 1               3           1               5   \n",
       "\n",
       "   v_score_text  priors_count.1  start  end  event  two_year_recid  \n",
       "1             1               0      9  159      1               1  \n",
       "2             1               4      0   63      0               1  \n",
       "6             1              14      5   40      1               1  \n",
       "8             1               0      2  747      0               0  \n",
       "9             2               1      0  428      1               1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we replace categorical columns with numeric values\n",
    "df_num = df.copy()\n",
    "feat2name = {}\n",
    "encoders = {}\n",
    "\n",
    "# Use Label Encoder for categorical columns (including target column)\n",
    "for feature in catogory_features:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df_num[feature])\n",
    "    \n",
    "    df_num[feature] = encoder.transform(df_num[feature])\n",
    "    \n",
    "    feat2name[feature] = encoder.classes_\n",
    "    encoders[feature] = encoder\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9bf0bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African-American', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['race'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603597ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(df_num, test_size=0.2)\n",
    "data_train, data_val= train_test_split(data_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c911325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will define some of the constants and functions mentioned in the paper\n",
    "N = df.shape[0]  # number of samples in X\n",
    "D = df.shape[1]  # Dimension of x vector\n",
    "K = 10  # Number of prototypes represented in Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f1a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(x1, x2, alpha):\n",
    "    \"\"\"\n",
    "        Calculates the euclidean distance between x1 and x2 with feature weights alpha\n",
    "        x1: First vector in X vector space (D, 1)\n",
    "        x2: Second vector in X vector space (D, 1)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    x1 = np.matrix(x1)\n",
    "    x2 = np.matrix(x2)\n",
    "    alpha = np.matrix(alpha)\n",
    "#     print(x1, x2, alpha)\n",
    "#     print(np.multiply(np.multiply((x1 - x2), (x1 - x2)),alpha))\n",
    "    return sum(np.multiply(np.multiply((x1 - x2), (x1 - x2)), alpha))[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c52fd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test \n",
    "d(np.matrix([1,2,3]).T, np.matrix([0,0,0]).T, np.matrix([1,1,2]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b74ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time for later, we will cache the distance map between all inputs X_i \n",
    "# and current prototypes V_k\n",
    "def d_map(X, V, alpha):\n",
    "    \"\"\"\n",
    "        Returns a 2D matrix with shape (N, K) with each cell (i, j) \n",
    "            distance from input x_i to prototype v_j with weighted features\n",
    "        X: Input matrix (N, D)\n",
    "        V: Prototype matrix (K, D)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    distance_map = np.zeros((X.shape[0], V.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            distance_map[i, j] = d(X[i, :], V[j, :], alpha)\n",
    "            \n",
    "    return distance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e714ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162.,   8.],\n",
       "       [ 98.,   0.],\n",
       "       [ 32.,  18.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "d_map(np.matrix([[1,2],[3,4],[6,7]]), np.matrix([[10,2],[3,40]]), np.matrix([[1.0],[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d5eaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_nk(X, n, V, k, alpha, dist_map, summation):\n",
    "    \"\"\"\n",
    "        Calculate the prob of X_n is classified to kth prototype using softmax\n",
    "        X: Input matrix (N, D)\n",
    "        n: the nth input to calculate the prob for\n",
    "        V: prototype matrix (K, D)\n",
    "        k: the kth prototype to classify for\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    p = 0\n",
    "    exponent = np.exp(-1 * dist_map[n, k])\n",
    "    p = exponent / summation\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3534b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time later, we will cache the probs of each x mapped to k\n",
    "def M_map(X, V, alpha):\n",
    "    \"\"\"\n",
    "        Return the prob of each x mapping to a prototype v (N, K)\n",
    "        X: Input matrix (N, D)\n",
    "        V: Prototype matrix (K, D)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    M = np.zeros((X.shape[0], V.shape[0]))\n",
    "    \n",
    "    dist_map = d_map(X, V, alpha)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            summation = 0\n",
    "            for k_idx in range(V.shape[0]):\n",
    "                summation += np.exp(-1 * dist_map[i, k_idx])\n",
    "            # To avoid value error\n",
    "            if (summation == 0): \n",
    "                summation = 0.000001\n",
    "            M[i, j] = M_nk(X, i, V, j, alpha, dist_map, summation)\n",
    "    return M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "574d24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_sub_k(M_sub_map):\n",
    "    \"\"\"\n",
    "        Calculate estimated prob of mapping to k for a subset M_map. (K,)\n",
    "        M_sub_map: prob of each x mapping to a prototype (N0, K)\n",
    "    \"\"\"\n",
    "    Ms = np.zeros(M_sub_map.shape[1])\n",
    "    \n",
    "    for k in range(M_sub_map.shape[1]):\n",
    "        for n in range(M_sub_map.shape[0]):\n",
    "            Ms[k] += M_sub_map[n, k]\n",
    "        Ms[k] /= M_sub_map.shape[0]\n",
    "    return Ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d59851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_hats(M, V):\n",
    "    \"\"\"\n",
    "        Return a matrix of reconstructed x through M \n",
    "            using each of the prototypes. (N, D)\n",
    "        M: M_map output (N, K)\n",
    "        V: Prototype matrix (K, D)\n",
    "    \"\"\"\n",
    "    return np.matmul(M, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db6a4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_hats(M, w):\n",
    "    \"\"\"\n",
    "        Return matrix of final estimates of each input through M and trained w.\n",
    "        M: M_map output (N, K)\n",
    "        w: Model weight between 0 and 1 (K, 1)\n",
    "    \"\"\"\n",
    "    y_hat = np.zeros(M.shape[0])\n",
    "    for n in range(M.shape[0]):\n",
    "        for k in range(M.shape[1]):\n",
    "            y_hat[n] += (M[n, k] * w[k])\n",
    "        # Clipping estimates to (0, 1)\n",
    "        y_hat[n] = 0.000001 if y_hat[n] <= 0 else y_hat[n]\n",
    "        y_hat[n] = 0.999999 if y_hat[n] >= 1 else y_hat[n]\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df127ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_x(X, x_hats):\n",
    "    \"\"\"\n",
    "        Loss term for goodness of the prototype.\n",
    "        X: input matrix (N, D)\n",
    "        x_hats: x estimates (N, D)\n",
    "    \"\"\"\n",
    "    Lx = 0\n",
    "    for n in range(X.shape[0]):\n",
    "        for d in range(X.shape[1]):\n",
    "            Lx += (X[n, d] - x_hats[n, d]) * (X[n, d] - x_hats[n, d])\n",
    "    return Lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20c28526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_y(ys, y_hats):\n",
    "    \"\"\"\n",
    "        Loss term for accuracy of the model\n",
    "        ys: Gound-truth label of X (N, 1)\n",
    "        y_hats: y estimates (N, 1)\n",
    "    \"\"\"\n",
    "    Ly = 0\n",
    "    for n in range(ys.shape[0]): \n",
    "        Ly += (-1 * ys[n] * np.log(y_hats[n]) - (1 - ys[n]) * (np.log(1 - y_hats[n])))\n",
    "    return Ly[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c937001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_z(M_sens, M_nonsens):\n",
    "    \"\"\"\n",
    "        Loss term for fairness.\n",
    "        M_sens: M_sub_k for sensitive data (1, K)\n",
    "        M_nonsens: M_sub_k for non-sensitive data (1, K)\n",
    "    \"\"\"\n",
    "    Lz= 0.0\n",
    "    \n",
    "    for k in range(M_sens.shape[0]):\n",
    "          Lz += abs(M_sens[k] - M_nonsens[k])\n",
    "    return Lz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04fe2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFR():\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data,\n",
    "        label_column,\n",
    "        sensitive_column,\n",
    "        privileged_group,\n",
    "        k,\n",
    "        A_x,\n",
    "        A_y,\n",
    "        A_z\n",
    "    ):\n",
    "        self.k = k\n",
    "        self.A_x = A_x\n",
    "        self.A_y = A_y\n",
    "        self.A_z = A_z\n",
    "        \n",
    "        self.__name__ = str(k) + \" \" + str(A_x) + \" \" + str(A_y) + \" \" + str(A_z) \n",
    "        \n",
    "        self.curr_iters = 0\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.label_column = label_column\n",
    "        self.sensitive_column = sensitive_column\n",
    "        self.privileged_group = privileged_group\n",
    "        \n",
    "        train_copy = train_data.copy()\n",
    "        train_copy.drop(columns=[label_column])\n",
    "        self.X = np.matrix(train_copy.to_numpy())\n",
    "        self.y = np.matrix(train_data[label_column].to_numpy()).T\n",
    "        \n",
    "        sens = train_data[sensitive_column]\n",
    "        priv_idx = np.array(np.where(sens==privileged_group))[0].flatten()\n",
    "        nonpriv_idx = np.array(np.where(sens!=privileged_group))[0].flatten()\n",
    "        self.X_plus = self.X[priv_idx,:]\n",
    "        self.y_plus = self.y[priv_idx,:]\n",
    "        self.X_minus = self.X[nonpriv_idx,:]\n",
    "        self.y_minus = self.y[nonpriv_idx,:]\n",
    "        \n",
    "    def fit(self, init_params, maxiters=100):\n",
    "        bnd = []\n",
    "        for i, k2 in enumerate(init_params):\n",
    "            if i < self.X.shape[1] * 2 or i >= self.X.shape[1] * 2 + self.k:\n",
    "                bnd.append((None, None))\n",
    "            else:\n",
    "                bnd.append((0, 1))\n",
    "        self.curr_param = init_params\n",
    "#         return\n",
    "        return optim.fmin_l_bfgs_b(self.forward, x0=init_params, epsilon=1e-5, \n",
    "                          bounds = bnd, approx_grad=True, maxfun=maxiters, maxiter=maxiters)\n",
    "        \n",
    "    def forward(self, params, return_params=False):\n",
    "        \"\"\"\n",
    "            \n",
    "        \"\"\"\n",
    "        self.curr_iters += 1\n",
    "        \n",
    "#         print(\"N_priv\")\n",
    "\n",
    "        N_priv, D = self.X_plus.shape\n",
    "        N_nonpriv, _ = self.X_minus.shape\n",
    "\n",
    "#         print(\"Extract\")\n",
    "        # Extract all params\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(params)\n",
    "\n",
    "#         print(\"Ms\")\n",
    "        M_k_p = M_map(self.X_plus, V, alpha_priv)\n",
    "        M_k_n = M_map(self.X_minus, V, alpha_nonpriv)\n",
    "\n",
    "#         print(\"Lz\")\n",
    "        Lz = L_z(M_sub_k(M_k_p), M_sub_k(M_k_n))\n",
    "\n",
    "#         print(\"Xhats\")\n",
    "        # To save time, we will just sum the two groups up\n",
    "        x_hats_p = x_hats(M_k_p, V)\n",
    "        x_hats_n = x_hats(M_k_n, V)\n",
    "#         print(\"Lx\")\n",
    "        L_x_p = L_x(self.X_plus, x_hats_p)\n",
    "        L_x_n = L_x(self.X_minus, x_hats_n)\n",
    "\n",
    "        Lx = L_x_p + L_x_n\n",
    "\n",
    "#         print(\"Yhats\")\n",
    "        y_hats_p = y_hats(M_k_p, w)\n",
    "        y_hats_n = y_hats(M_k_n, w)\n",
    "#         print(\"Ly\")\n",
    "        L_y_p = L_y(self.y_plus, y_hats_p)\n",
    "        L_y_n = L_y(self.y_minus, y_hats_n)\n",
    "\n",
    "        Ly = L_y_p + L_y_n\n",
    "\n",
    "#         print(\"Loss\", Lx, Ly, Lz)\n",
    "        loss = (self.A_x * Lx) + (self.A_y * Ly) + (self.A_z * Lz)\n",
    "\n",
    "        if self.curr_iters % 50 == 0:\n",
    "            print(\n",
    "                \"model:\", self.__name__,\n",
    "                \"step:\", self.curr_iters, \n",
    "                \"loss:\", loss, \n",
    "                \"Lx:\", Lx, \n",
    "                \"Ly:\", Ly, \n",
    "                \"Lz:\", Lz)\n",
    "#             print(\"params y_hats_p, y_hats_n, M_k_p, M_k_n, loss:\",\n",
    "#                  y_hats_p, y_hats_n, M_k_p, M_k_n, loss)\n",
    "\n",
    "        self.curr_param = params\n",
    "\n",
    "        if return_params:\n",
    "            return y_hats_p, y_hats_n, M_k_p, M_k_n, loss\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "    def extract_param(self, params):\n",
    "        \n",
    "        _, D = self.X_plus.shape\n",
    "        # Extract all params\n",
    "        alpha_priv = params[:D].T\n",
    "        alpha_nonpriv = params[D:2*D].T\n",
    "\n",
    "        w = params[2*D:2*D+self.k]\n",
    "        V = np.matrix(params[(2*D)+self.k:]).reshape((self.k, D))\n",
    "        return alpha_priv, alpha_nonpriv, w, V\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(self.curr_param)\n",
    "        \n",
    "        M_k_p = M_map(X_test, V, alpha_priv)\n",
    "        \n",
    "        return y_hats(M_k_p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce5c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(init_param, maxiters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4993fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see the model has reached minima at step 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4b8a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5 1e-06 0.001 1 step: 50 loss: 1632.480007875939 Lx: 1630339996.2395477 Ly: 2123.3838270876886 Lz: 0.016627809303629698\n",
      "model: 5 1e-06 0.001 1 step: 100 loss: 1632.4800062824963 Lx: 1630339996.244298 Ly: 2123.38222889491 Lz: 0.016627809303629698\n",
      "model: 5 1e-06 0.001 1 step: 150 loss: 1632.4800062770485 Lx: 1630339996.23885 Ly: 2123.38222889491 Lz: 0.016627809303629698\n",
      "model: 5 1e-06 0.001 1 step: 200 loss: 1631.0891437856137 Lx: 1628969123.3763192 Ly: 2102.741102718468 Lz: 0.017279306576078957\n",
      "model: 5 1e-06 0.001 1 step: 250 loss: 1631.0891437472924 Lx: 1628969123.337998 Ly: 2102.741102718468 Lz: 0.017279306576078957\n",
      "model: 5 1e-06 0.001 1 step: 300 loss: 1631.0891437859261 Lx: 1628969123.3766317 Ly: 2102.741102718468 Lz: 0.017279306576078957\n",
      "model: 5 1e-06 0.001 1 step: 350 loss: 1629.2880014555099 Lx: 1608846904.9226294 Ly: 20281.171059092336 Lz: 0.15992547378832375\n",
      "model: 5 1e-06 0.001 1 step: 400 loss: 1629.2880014113528 Lx: 1608846904.8784723 Ly: 20281.171059092336 Lz: 0.15992547378832375\n",
      "model: 5 1e-06 0.001 1 step: 450 loss: 1629.2880014082236 Lx: 1608846904.8753433 Ly: 20281.171059092336 Lz: 0.15992547378832375\n",
      "model: 5 1e-06 0.001 1 step: 500 loss: 1631.0873687499927 Lx: 1628967318.3785508 Ly: 2102.7571324556666 Lz: 0.017293238986142295\n",
      "model: 5 1e-06 0.001 1 step: 550 loss: 1631.0873622674746 Lx: 1628967311.8960328 Ly: 2102.7571324556666 Lz: 0.017293238986142295\n",
      "model: 5 1e-06 0.001 1 step: 600 loss: 1631.0873687603025 Lx: 1628967318.3888607 Ly: 2102.7571324556666 Lz: 0.017293238986142295\n",
      "model: 5 1e-06 0.001 1 step: 650 loss: 1621.5367226352391 Lx: 1618873480.8998823 Ly: 2582.7191610071 Lz: 0.08052257434976792\n",
      "model: 5 1e-06 0.001 1 step: 700 loss: 1621.5367221301908 Lx: 1618873480.394834 Ly: 2582.7191610071 Lz: 0.08052257434976792\n",
      "model: 5 1e-06 0.001 1 step: 750 loss: 1621.5367225970053 Lx: 1618873480.8616486 Ly: 2582.7191610071 Lz: 0.08052257434976792\n",
      "model: 5 1e-06 0.001 1 step: 800 loss: 1621.5367226354729 Lx: 1618873480.900116 Ly: 2582.7191610071 Lz: 0.08052257434976792\n",
      "model: 5 1e-06 0.001 1 step: 50 loss: 1616.4838798280603 Lx: 1614342163.5141153 Ly: 2124.3652314543874 Lz: 0.017351082490509873\n",
      "model: 5 1e-06 0.001 1 step: 100 loss: 1616.4838781833141 Lx: 1614342163.518931 Ly: 2124.363581892839 Lz: 0.017351082490509873\n",
      "model: 5 1e-06 0.001 1 step: 150 loss: 1616.4838781778394 Lx: 1614342163.5134563 Ly: 2124.363581892839 Lz: 0.017351082490509873\n",
      "model: 5 1e-06 0.001 1 step: 200 loss: 1615.1099628341797 Lx: 1612990514.7904186 Ly: 2102.8268401022547 Lz: 0.016621203658702094\n",
      "model: 5 1e-06 0.001 1 step: 250 loss: 1615.1099627959436 Lx: 1612990514.7521825 Ly: 2102.8268401022547 Lz: 0.016621203658702094\n",
      "model: 5 1e-06 0.001 1 step: 300 loss: 1615.109962834431 Lx: 1612990514.79067 Ly: 2102.8268401022547 Lz: 0.016621203658702094\n",
      "model: 5 1e-06 0.001 1 step: 350 loss: 1604.533054756228 Lx: 1594260902.2767284 Ly: 10144.223789683581 Lz: 0.12792868981622268\n",
      "model: 5 1e-06 0.001 1 step: 400 loss: 1604.5330547126548 Lx: 1594260902.2331553 Ly: 10144.223789683581 Lz: 0.12792868981622268\n",
      "model: 5 1e-06 0.001 1 step: 450 loss: 1604.5330547083543 Lx: 1594260902.2288547 Ly: 10144.223789683581 Lz: 0.12792868981622268\n",
      "model: 5 1e-06 0.001 1 step: 500 loss: 1614.6016016712015 Lx: 1612472069.2363515 Ly: 2108.949005246005 Lz: 0.020583429604163123\n",
      "model: 5 1e-06 0.001 1 step: 550 loss: 1614.6015952902383 Lx: 1612472062.8553884 Ly: 2108.949005246005 Lz: 0.020583429604163123\n",
      "model: 5 1e-06 0.001 1 step: 600 loss: 1614.6016016813671 Lx: 1612472069.2465172 Ly: 2108.949005246005 Lz: 0.020583429604163123\n",
      "model: 5 1e-06 0.001 1 step: 650 loss: 1606.0236418194963 Lx: 1603337610.1536937 Ly: 2608.9099058090605 Lz: 0.07712175999371887\n",
      "model: 5 1e-06 0.001 1 step: 700 loss: 1606.023641333094 Lx: 1603337609.6672912 Ly: 2608.9099058090605 Lz: 0.07712175999371887\n",
      "model: 5 1e-06 0.001 1 step: 750 loss: 1606.0236417811398 Lx: 1603337610.115337 Ly: 2608.9099058090605 Lz: 0.07712175999371887\n",
      "model: 5 1e-06 0.001 1 step: 800 loss: 1606.02364181974 Lx: 1603337610.1539373 Ly: 2608.9099058090605 Lz: 0.07712175999371887\n",
      "model: 5 1e-06 0.001 1 step: 50 loss: 1686.4032134067145 Lx: 1684254863.4528503 Ly: 2131.542328486816 Lz: 0.01680762537739436\n",
      "model: 5 1e-06 0.001 1 step: 100 loss: 1686.4032114823376 Lx: 1684254863.4576607 Ly: 2131.5403992996257 Lz: 0.01680762537739436\n",
      "model: 5 1e-06 0.001 1 step: 150 loss: 1686.4032114769723 Lx: 1684254863.4522953 Ly: 2131.5403992996257 Lz: 0.01680762537739436\n",
      "model: 5 1e-06 0.001 1 step: 200 loss: 1684.9987263267985 Lx: 1682882203.898505 Ly: 2100.0302420312364 Lz: 0.01649218626235832\n",
      "model: 5 1e-06 0.001 1 step: 250 loss: 1684.9987262901504 Lx: 1682882203.861857 Ly: 2100.0302420312364 Lz: 0.01649218626235832\n",
      "model: 5 1e-06 0.001 1 step: 300 loss: 1684.9987263271623 Lx: 1682882203.8988688 Ly: 2100.0302420312364 Lz: 0.01649218626235832\n",
      "model: 5 1e-06 0.001 1 step: 350 loss: 1671.95514635563 Lx: 1666080762.1687632 Ly: 5756.968799863809 Lz: 0.1174153870029056\n",
      "model: 5 1e-06 0.001 1 step: 400 loss: 1671.9551463140801 Lx: 1666080762.1272135 Ly: 5756.968799863809 Lz: 0.1174153870029056\n",
      "model: 5 1e-06 0.001 1 step: 450 loss: 1671.9551463079104 Lx: 1666080762.1210437 Ly: 5756.968799863809 Lz: 0.1174153870029056\n",
      "model: 5 1e-06 0.001 1 step: 500 loss: 1676.913011267474 Lx: 1674307514.9871604 Ly: 2541.9487963885117 Lz: 0.06354748392507456\n",
      "model: 5 1e-06 0.001 1 step: 550 loss: 1676.913004941827 Lx: 1674307508.6615133 Ly: 2541.9487963885117 Lz: 0.06354748392507456\n",
      "model: 5 1e-06 0.001 1 step: 600 loss: 1676.913011277422 Lx: 1674307514.9971082 Ly: 2541.9487963885117 Lz: 0.06354748392507456\n",
      "model: 5 1e-06 0.001 1 step: 50 loss: 1668.5110348152325 Lx: 1666369520.8890114 Ly: 2124.931732242453 Lz: 0.016582193978899457\n",
      "model: 5 1e-06 0.001 1 step: 100 loss: 1668.511033157004 Lx: 1666369520.8937802 Ly: 2124.9300692450906 Lz: 0.016582193978899457\n",
      "model: 5 1e-06 0.001 1 step: 150 loss: 1668.5110331515475 Lx: 1666369520.8883238 Ly: 2124.9300692450906 Lz: 0.016582193978899457\n",
      "model: 5 1e-06 0.001 1 step: 200 loss: 1667.124814830915 Lx: 1665004818.2227802 Ly: 2102.555679303129 Lz: 0.017440928831743446\n",
      "model: 5 1e-06 0.001 1 step: 250 loss: 1667.1248147930041 Lx: 1665004818.1848693 Ly: 2102.555679303129 Lz: 0.017440928831743446\n",
      "model: 5 1e-06 0.001 1 step: 300 loss: 1667.1248148311545 Lx: 1665004818.2230196 Ly: 2102.555679303129 Lz: 0.017440928831743446\n",
      "model: 5 1e-06 0.001 1 step: 350 loss: 1657.9767111903266 Lx: 1645891325.017365 Ly: 11948.493100051517 Lz: 0.13689307291008745\n",
      "model: 5 1e-06 0.001 1 step: 400 loss: 1657.976711147141 Lx: 1645891324.9741793 Ly: 11948.493100051517 Lz: 0.13689307291008745\n",
      "model: 5 1e-06 0.001 1 step: 450 loss: 1657.9767111425338 Lx: 1645891324.969572 Ly: 11948.493100051517 Lz: 0.13689307291008745\n",
      "model: 5 1e-06 0.001 1 step: 500 loss: 1666.9718394090542 Lx: 1664849105.8418493 Ly: 2104.12566536766 Lz: 0.01860790183728883\n",
      "model: 5 1e-06 0.001 1 step: 550 loss: 1666.9718329442205 Lx: 1664849099.3770156 Ly: 2104.12566536766 Lz: 0.01860790183728883\n",
      "model: 5 1e-06 0.001 1 step: 600 loss: 1666.9718394193362 Lx: 1664849105.8521314 Ly: 2104.12566536766 Lz: 0.01860790183728883\n",
      "model: 5 1e-06 0.001 1 step: 650 loss: 1658.0023484501182 Lx: 1655337608.3627577 Ly: 2588.2186549084477 Lz: 0.07652143245218884\n",
      "model: 5 1e-06 0.001 1 step: 700 loss: 1658.0023479267613 Lx: 1655337607.8394008 Ly: 2588.2186549084477 Lz: 0.07652143245218884\n",
      "model: 5 1e-06 0.001 1 step: 750 loss: 1658.0023484114295 Lx: 1655337608.324069 Ly: 2588.2186549084477 Lz: 0.07652143245218884\n",
      "model: 5 1e-06 0.001 1 step: 800 loss: 1658.0023484504438 Lx: 1655337608.3630834 Ly: 2588.2186549084477 Lz: 0.07652143245218884\n",
      "model: 5 1e-06 0.001 1 step: 50 loss: 1530.3575749900904 Lx: 1528218139.2336192 Ly: 2122.6868563032194 Lz: 0.016748900167941727\n",
      "model: 5 1e-06 0.001 1 step: 100 loss: 1530.3575734208798 Lx: 1528218139.2384396 Ly: 2122.6852822723918 Lz: 0.016748900167941727\n",
      "model: 5 1e-06 0.001 1 step: 150 loss: 1530.357573415355 Lx: 1528218139.232915 Ly: 2122.6852822723918 Lz: 0.016748900167941727\n",
      "model: 5 1e-06 0.001 1 step: 200 loss: 1528.9805033621244 Lx: 1526860655.2115328 Ly: 2103.1210543278216 Lz: 0.016727096263768088\n",
      "model: 5 1e-06 0.001 1 step: 250 loss: 1528.980503324289 Lx: 1526860655.1736975 Ly: 2103.1210543278216 Lz: 0.016727096263768088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5 1e-06 0.001 1 step: 300 loss: 1528.9805033625244 Lx: 1526860655.2119327 Ly: 2103.1210543278216 Lz: 0.016727096263768088\n",
      "model: 5 1e-06 0.001 1 step: 350 loss: 1527.403642429951 Lx: 1506928187.2276273 Ly: 20322.617587766224 Lz: 0.15283761455767816\n",
      "model: 5 1e-06 0.001 1 step: 400 loss: 1527.4036423864889 Lx: 1506928187.184165 Ly: 20322.617587766224 Lz: 0.15283761455767816\n",
      "model: 5 1e-06 0.001 1 step: 450 loss: 1527.4036423821656 Lx: 1506928187.1798418 Ly: 20322.617587766224 Lz: 0.15283761455767816\n",
      "model: 5 1e-06 0.001 1 step: 500 loss: 1528.9787652125578 Lx: 1526858887.050724 Ly: 2103.137228506222 Lz: 0.0167409333275228\n",
      "model: 5 1e-06 0.001 1 step: 550 loss: 1528.9787587945784 Lx: 1526858880.6327446 Ly: 2103.137228506222 Lz: 0.0167409333275228\n",
      "model: 5 1e-06 0.001 1 step: 600 loss: 1528.978765222777 Lx: 1526858887.0609431 Ly: 2103.137228506222 Lz: 0.0167409333275228\n",
      "model: 5 1e-06 0.001 1 step: 650 loss: 1519.5243575596317 Lx: 1516859432.5363145 Ly: 2585.711463611522 Lz: 0.07921355970580429\n",
      "model: 5 1e-06 0.001 1 step: 700 loss: 1519.5243571047924 Lx: 1516859432.0814753 Ly: 2585.711463611522 Lz: 0.07921355970580429\n",
      "model: 5 1e-06 0.001 1 step: 750 loss: 1519.5243575211061 Lx: 1516859432.497789 Ly: 2585.711463611522 Lz: 0.07921355970580429\n",
      "model: 5 1e-06 0.001 1 step: 800 loss: 1519.5243575598975 Lx: 1516859432.5365803 Ly: 2585.711463611522 Lz: 0.07921355970580429\n",
      "5 1e-06 0.001 1 mean val MAE: 0.48984309384539826\n",
      "Time lapsed 3556440.681695938\n",
      "5 1e-06 0.001 1 0.48984309384539826\n"
     ]
    }
   ],
   "source": [
    "# Compute MAE\n",
    "def compute_error(y_hat, y):\n",
    "    # mean absolute error\n",
    "    return np.abs(y_hat - y).mean()\n",
    "\n",
    "# Vars to store results\n",
    "cval_errs = {} # Mean validation errors\n",
    "train_time = {} # Training time\n",
    "# Best Model\n",
    "best_model = None\n",
    "# Best Validation Error\n",
    "best_err = sys.maxsize\n",
    "\n",
    "# Model selection \n",
    "KS = [5]#, 10]\n",
    "Axs = [0.00000001]#, 1, 1000000]\n",
    "Ays = [0.01]#, 1, 1000]\n",
    "Azs = [1000]#, 10000, 1000000]\n",
    "\n",
    "train_data = data_train.copy()\n",
    "\n",
    "for K in KS:\n",
    "    init_param = np.random.uniform(size=df.shape[1] * 2 + K + df.shape[1] * K)\n",
    "    for Ax in Axs:\n",
    "        for Ay in Ays:    \n",
    "            for Az in Azs:\n",
    "                kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "                y_err = []\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                # Cross Validaiton\n",
    "                for train_index, val_index in kf.split(train_data):\n",
    "                #     print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n",
    "                    train_copy = train_data.copy()\n",
    "                    train_copy.drop(columns=[label_column])\n",
    "                    train_df = train_copy.iloc[train_index]\n",
    "                    \n",
    "                    X_val = np.matrix(train_copy.iloc[val_index].to_numpy())\n",
    "                    y_val = np.matrix(train_data.iloc[val_index][label_column].to_numpy()).T\n",
    "\n",
    "                    model = LFR(\n",
    "                        train_df,\n",
    "                        \"two_year_recid\",\n",
    "                        \"race\",\n",
    "                        1,\n",
    "                        K,\n",
    "                        Ax,\n",
    "                        Ay,\n",
    "                        Az\n",
    "                    )\n",
    "                    model.fit(init_param, maxiters=500)\n",
    "                    \n",
    "                    y_hat = model.predict(X_val)\n",
    "                #     print(y_hat)\n",
    "                    y_err.append(compute_error(y_hat, y_val))\n",
    "\n",
    "                end = time.time()\n",
    "\n",
    "                print(str(K), str(Ax), str(Ay), str(Az), \"mean val MAE:\", np.mean(y_err))\n",
    "                print(\"Time lapsed\", str((end - start)*1000))\n",
    "\n",
    "                # add to dict\n",
    "                cval_errs[model.__name__] = np.mean(y_err)\n",
    "                train_time[model.__name__] = (end - start)*1000\n",
    "                if np.mean(y_err) < best_err:\n",
    "                    best_model = model\n",
    "                    best_err = np.mean(y_err)\n",
    "                    best_errs = y_err\n",
    "                \n",
    "print(best_model.__name__, best_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85ccd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d13792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9453de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_param = np.random.uniform(size=df.shape[1] * 2 + K + df.shape[1] * K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1dab3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 1e-08 0.01 1000'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "label_column = \"two_year_recid\"\n",
    "model = LFR(\n",
    "    data_train,\n",
    "    label_column,\n",
    "    \"race\",\n",
    "    1,\n",
    "    K,\n",
    "    0.00000001,\n",
    "    0.01,\n",
    "    1000\n",
    ")\n",
    "model.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5 1e-08 0.01 1000 step: 50 loss: 63.69863086276577 Lx: 2030881170.8322392 Ly: 2656.7253904012214 Lz: 0.01682256525043116\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 63.69863086276951 Lx: 2030881170.8326135 Ly: 2656.7253904012214 Lz: 0.01682256525043116\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 63.69863086282634 Lx: 2030881170.838297 Ly: 2656.7253904012214 Lz: 0.01682256525043116\n",
      "model: 5 1e-08 0.01 1000 step: 200 loss: 199.59735743896843 Lx: 2030888857.8887005 Ly: 2648.671078034471 Lz: 0.15280175807973673\n"
     ]
    }
   ],
   "source": [
    "model.fit(init_param, maxiters=15000)\n",
    "# Predict\n",
    "test_copy = data_test.copy()\n",
    "test_copy.drop(columns=[label_column])\n",
    "\n",
    "X_test = np.matrix(test_copy.to_numpy())\n",
    "y_test = np.matrix(data_test[label_column].to_numpy()).T\n",
    "y_hat = model.predict(X_test)\n",
    "print(\"error:\", compute_error(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667a5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
