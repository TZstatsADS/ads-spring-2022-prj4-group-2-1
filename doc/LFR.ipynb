{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05cfc18",
   "metadata": {},
   "source": [
    "# # A1 Learning Fair Representations (LFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5ff6d",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d960fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.optimize as optim\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5424c1",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e1ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/compas-scores-two-years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670edc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 06:03:42</td>\n",
       "      <td>2013-08-14 05:41:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-26 03:45:27</td>\n",
       "      <td>2013-02-05 05:36:53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-13 04:58:34</td>\n",
       "      <td>2013-04-14 07:02:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-30 04:50:18</td>\n",
       "      <td>2013-12-01 12:28:56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-18 05:08:24</td>\n",
       "      <td>2014-02-24 12:18:30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-22 05:18:27</td>\n",
       "      <td>2013-11-24 02:59:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-31 07:13:54</td>\n",
       "      <td>2014-02-02 04:03:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-13 05:48:01</td>\n",
       "      <td>2014-01-14 07:49:46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-03-08 08:06:02</td>\n",
       "      <td>2014-03-09 12:18:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-28 12:16:41</td>\n",
       "      <td>2014-06-30 11:19:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age c_charge_degree              race          age_cat score_text  \\\n",
       "0      69               F             Other  Greater than 45        Low   \n",
       "1      34               F  African-American          25 - 45        Low   \n",
       "2      24               F  African-American     Less than 25        Low   \n",
       "5      44               M             Other          25 - 45        Low   \n",
       "6      41               F         Caucasian          25 - 45     Medium   \n",
       "...   ...             ...               ...              ...        ...   \n",
       "7209   23               F  African-American     Less than 25     Medium   \n",
       "7210   23               F  African-American     Less than 25        Low   \n",
       "7211   57               F             Other  Greater than 45        Low   \n",
       "7212   33               M  African-American          25 - 45        Low   \n",
       "7213   23               F          Hispanic     Less than 25        Low   \n",
       "\n",
       "         sex  priors_count  days_b_screening_arrest  decile_score  is_recid  \\\n",
       "0       Male             0                     -1.0             1         0   \n",
       "1       Male             0                     -1.0             3         1   \n",
       "2       Male             4                     -1.0             4         1   \n",
       "5       Male             0                      0.0             1         0   \n",
       "6       Male            14                     -1.0             6         1   \n",
       "...      ...           ...                      ...           ...       ...   \n",
       "7209    Male             0                     -1.0             7         0   \n",
       "7210    Male             0                     -1.0             3         0   \n",
       "7211    Male             0                     -1.0             1         0   \n",
       "7212  Female             3                     -1.0             2         0   \n",
       "7213  Female             2                     -2.0             4         1   \n",
       "\n",
       "                c_jail_in           c_jail_out  two_year_recid  \n",
       "0     2013-08-13 06:03:42  2013-08-14 05:41:20               0  \n",
       "1     2013-01-26 03:45:27  2013-02-05 05:36:53               1  \n",
       "2     2013-04-13 04:58:34  2013-04-14 07:02:04               1  \n",
       "5     2013-11-30 04:50:18  2013-12-01 12:28:56               0  \n",
       "6     2014-02-18 05:08:24  2014-02-24 12:18:30               1  \n",
       "...                   ...                  ...             ...  \n",
       "7209  2013-11-22 05:18:27  2013-11-24 02:59:20               0  \n",
       "7210  2014-01-31 07:13:54  2014-02-02 04:03:52               0  \n",
       "7211  2014-01-13 05:48:01  2014-01-14 07:49:46               0  \n",
       "7212  2014-03-08 08:06:02  2014-03-09 12:18:04               0  \n",
       "7213  2014-06-28 12:16:41  2014-06-30 11:19:23               1  \n",
       "\n",
       "[6172 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw[['age', 'c_charge_degree', 'race', 'age_cat',\n",
    "                    'score_text', 'sex', 'priors_count', 'days_b_screening_arrest',\n",
    "                    'decile_score', 'is_recid', 'c_jail_in',\n",
    "                    'c_jail_out', 'two_year_recid']]\\\n",
    "                    .query('days_b_screening_arrest <= 30')\\\n",
    "                    .query('days_b_screening_arrest >= -30')\\\n",
    "                    .query('is_recid != -1')\\\n",
    "                    .query('c_charge_degree != \"O\"')\\\n",
    "                    .query('score_text != \"N/A\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35151005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unrelated columns\n",
    "df = df[(df.race=='African-American') | (df.race=='Caucasian')]\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9deb71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "dt1 = list(map(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date(), df['c_jail_out']))\n",
    "dt2 = list(map(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date(), df['c_jail_in']))\n",
    "\n",
    "len_stay = [(a-b).days for a,b in zip(dt1,dt2)]\n",
    "\n",
    "df['length_of_stay'] = len_stay\n",
    "df = df.drop(['c_jail_out', 'c_jail_in'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e6c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns so y is the last column\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[:-2] + cols[-1:] + cols[-2:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d64aa9",
   "metadata": {},
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81f73a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical: ['c_charge_degree', 'race', 'age_cat', 'score_text', 'sex']\n",
      "numerical: ['age', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid', 'length_of_stay']\n"
     ]
    }
   ],
   "source": [
    "label_column = ['two_year_recid']\n",
    "catogory_features = []\n",
    "numeric_features = []\n",
    "\n",
    "for col in df.columns.values:\n",
    "    if col in label_column:\n",
    "        continue\n",
    "    elif df[col].dtypes in ('int64', 'float64') :\n",
    "        numeric_features += [col]\n",
    "    else:\n",
    "        catogory_features += [col]\n",
    "        \n",
    "print(\"categorical:\", catogory_features)\n",
    "print(\"numerical:\", numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59453091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we replace categorical columns with numeric values\n",
    "df_num = df.copy()\n",
    "feat2name = {}\n",
    "encoders = {}\n",
    "\n",
    "# Use Label Encoder for categorical columns (including target column)\n",
    "for feature in catogory_features:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df_num[feature])\n",
    "    \n",
    "    df_num[feature] = encoder.transform(df_num[feature])\n",
    "    \n",
    "    feat2name[feature] = encoder.classes_\n",
    "    encoders[feature] = encoder\n",
    "\n",
    "# Use MinMaxScaler for numerical columns     \n",
    "for feature in numeric_features:\n",
    "    val = df_num[feature].values[:, np.newaxis]\n",
    "    mms = MinMaxScaler().fit(val)\n",
    "    df_num[feature] = mms.transform(val)\n",
    "    encoders[feature] = mms\n",
    "    \n",
    "df_num = df_num.astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ac76ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African-American', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['race'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205f1c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a155765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.338710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  c_charge_degree  race  age_cat  score_text  sex  priors_count  \\\n",
       "1   0.258065              0.0   0.0      0.0         1.0  1.0      0.000000   \n",
       "2   0.096774              0.0   0.0      2.0         1.0  1.0      0.105263   \n",
       "6   0.370968              0.0   1.0      0.0         2.0  1.0      0.368421   \n",
       "8   0.338710              1.0   1.0      0.0         1.0  0.0      0.000000   \n",
       "10  0.145161              0.0   1.0      0.0         1.0  1.0      0.000000   \n",
       "\n",
       "    days_b_screening_arrest  decile_score  is_recid  length_of_stay  \\\n",
       "1                  0.483333      0.222222       1.0         0.01250   \n",
       "2                  0.483333      0.333333       1.0         0.00125   \n",
       "6                  0.483333      0.555556       1.0         0.00750   \n",
       "8                  0.483333      0.000000       0.0         0.00375   \n",
       "10                 0.483333      0.333333       0.0         0.00125   \n",
       "\n",
       "    two_year_recid  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "6              1.0  \n",
       "8              0.0  \n",
       "10             0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bf0bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African-American', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['race'].classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c931b1",
   "metadata": {},
   "source": [
    "## Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "603597ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(df_num, test_size=0.2)\n",
    "data_train, data_val= train_test_split(data_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c911325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will define some of the constants and functions mentioned in the paper\n",
    "N = df.shape[0]  # number of samples in X\n",
    "D = df.shape[1]  # Dimension of x vector\n",
    "K = 10  # Number of prototypes represented in Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2271d8",
   "metadata": {},
   "source": [
    "## LFR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9546a",
   "metadata": {},
   "source": [
    "The goal of LFR is to learn a good prototype set $Z$ such that:\n",
    "1. the mapping from $X_0$ to $Z$ satisfies statistical parity;\n",
    "2. the mapping to $Z$-space retains information in $X$ (except for membership in the protected set); and\n",
    "3. the induced mapping from $X$ to $Y$ (by first mapping each $x$ probabilistically to $Z$-space, and then mapping $Z$ to $Y$) is close to f.\n",
    "\n",
    "Each of these aims corresponds to a term in the objective function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef07e6a",
   "metadata": {},
   "source": [
    "## (1) Define "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8011e8f",
   "metadata": {},
   "source": [
    "We define $M_{nk}$ as the probability that $x_n$ maps to $v_k$.\n",
    "\n",
    "So,\n",
    "$$M_{nk} = P(Z=k|x_n) \\space\\space \n",
    "=\\frac{exp(-d(x_n, v_k))}{\\sum_{k=1}^K exp(-d(x_n, v_k))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04ce34",
   "metadata": {},
   "source": [
    "###  Calculates the euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496429af",
   "metadata": {},
   "source": [
    "$$d(x_n, v_k, \\alpha) = \\sum^D_{d=1} \\alpha_d (x_{nd} - v_{kd})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f1a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(x1, x2, alpha):\n",
    "    \"\"\"\n",
    "        Calculates the euclidean distance between x1 and x2 with feature weights alpha\n",
    "        x1: First vector in X vector space (D, 1)\n",
    "        x2: Second vector in X vector space (D, 1)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    x1 = np.matrix(x1)\n",
    "    x2 = np.matrix(x2)\n",
    "    alpha = np.matrix(alpha)\n",
    "#     print(x1, x2, alpha)\n",
    "#     print(np.multiply(np.multiply((x1 - x2), (x1 - x2)),alpha))\n",
    "    return sum(np.multiply(np.multiply((x1 - x2), (x1 - x2)), alpha))[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c52fd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test \n",
    "d(np.matrix([1,2,3]).T, np.matrix([0,0,0]).T, np.matrix([1,1,2]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b74ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time for later, we will cache the distance map between all inputs X_i \n",
    "# and current prototypes V_k\n",
    "def d_map(X, V, alpha):\n",
    "    \"\"\"\n",
    "        Returns a 2D matrix with shape (N, K) with each cell (i, j) \n",
    "            distance from input x_i to prototype v_j with weighted features\n",
    "        X: Input matrix (N, D)\n",
    "        V: Prototype matrix (K, D)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    distance_map = np.zeros((X.shape[0], V.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            distance_map[i, j] = d(X[i, :], V[j, :], alpha)\n",
    "            \n",
    "    return distance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e714ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162.,   8.],\n",
       "       [ 98.,   0.],\n",
       "       [ 32.,  18.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "d_map(np.matrix([[1,2],[3,4],[6,7]]), np.matrix([[10,2],[3,40]]), np.matrix([[1.0],[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d5eaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_nk(X, n, V, k, alpha, dist_map, summation):\n",
    "    \"\"\"\n",
    "        Calculate the prob of X_n is classified to kth prototype using softmax\n",
    "        X: Input matrix (N, D)\n",
    "        n: the nth input to calculate the prob for\n",
    "        V: prototype matrix (K, D)\n",
    "        k: the kth prototype to classify for\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    p = 0\n",
    "    exponent = np.exp(-1 * dist_map[n, k])\n",
    "    p = exponent / summation\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3534b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time later, we will cache the probs of each x mapped to k\n",
    "def M_map(X, V, alpha):\n",
    "    \"\"\"\n",
    "        Return the prob of each x mapping to a prototype v (N, K)\n",
    "        X: Input matrix (N, D)\n",
    "        V: Prototype matrix (K, D)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    M = np.zeros((X.shape[0], V.shape[0]))\n",
    "    \n",
    "    dist_map = d_map(X, V, alpha)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            summation = 0\n",
    "            for k_idx in range(V.shape[0]):\n",
    "                summation += np.exp(-1 * dist_map[i, k_idx])\n",
    "            # To avoid value error\n",
    "            if (summation == 0): \n",
    "                summation = 0.000001\n",
    "            M[i, j] = M_nk(X, i, V, j, alpha, dist_map, summation)\n",
    "    return M\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f616f0",
   "metadata": {},
   "source": [
    "$$M_k =\\mathop{\\mathbb{E}}_{x \\in X} P(Z=k|x)= \\frac{1}{|X|} \\sum_{n \\in X} M_{nk}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "574d24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_sub_k(M_sub_map):\n",
    "    \"\"\"\n",
    "        Calculate estimated prob of mapping to k for a subset M_map. (K,)\n",
    "        M_sub_map: prob of each x mapping to a prototype (N0, K)\n",
    "    \"\"\"\n",
    "    Ms = np.zeros(M_sub_map.shape[1])\n",
    "    \n",
    "    for k in range(M_sub_map.shape[1]):\n",
    "        for n in range(M_sub_map.shape[0]):\n",
    "            Ms[k] += M_sub_map[n, k]\n",
    "        Ms[k] /= M_sub_map.shape[0]\n",
    "    return Ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e70a9",
   "metadata": {},
   "source": [
    "## (2) Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37cc00",
   "metadata": {},
   "source": [
    "## \n",
    "<h1 align = \"center\">$Total \\space Loss = A_x * L_x + A_y * L_y + A_z * L_z 􏰂􏰀􏰀$<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657df402",
   "metadata": {},
   "source": [
    "where $A_x, A_y, A_z$ are hyper-parameters governing the trade-off between the system desiderata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6042fb",
   "metadata": {},
   "source": [
    "## <div align='center' ><font size='5'>$L_x = \\sum_{n=1}^N (x_n - \\hat{x}_n)^2$</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3121c",
   "metadata": {},
   "source": [
    "where $$\\hat{x}_n = \\sum^K_{k=1}M_{nk}v_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df127ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_x(X, x_hats):\n",
    "    \"\"\"\n",
    "        Loss term for goodness of the prototype.\n",
    "        X: input matrix (N, D)\n",
    "        x_hats: x estimates (N, D)\n",
    "    \"\"\"\n",
    "    Lx = 0\n",
    "    for n in range(X.shape[0]):\n",
    "        for d in range(X.shape[1]):\n",
    "            Lx += (X[n, d] - x_hats[n, d]) * (X[n, d] - x_hats[n, d])\n",
    "    return Lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14d59851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_hats(M, V):\n",
    "    \"\"\"\n",
    "        Return a matrix of reconstructed x through M \n",
    "            using each of the prototypes. (N, D)\n",
    "        M: M_map output (N, K)\n",
    "        V: Prototy$$\\hat{x}_n = \\sum^K_{k=1}M_{nk}v_k$$pe matrix (K, D)\n",
    "    \"\"\"\n",
    "    return np.matmul(M, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8aeb49",
   "metadata": {},
   "source": [
    "## <div align='center' ><font size='5'>$L_y = \\sum_{n=1}^N -y_n log \\hat{y}_n - (1-y_n)log(1- \\hat{y}_n)$</font></div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499a058",
   "metadata": {},
   "source": [
    "$$\\hat{y}_n = \\sum^K_{k=1} M_{nk}w_k \\\\\n",
    "0< w_k <1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20c28526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_y(ys, y_hats):\n",
    "    \"\"\"\n",
    "        Loss term for accuracy of the model\n",
    "        ys: Gound-truth ## $L_y = \\sum_{n=1}^N -y_n log \\hat{y}_n - (1-y_n)log(1- \\hat{y}_n)$label of X (N, 1)\n",
    "        y_hats: y estimates (N, 1)\n",
    "    \"\"\"\n",
    "    Ly = 0\n",
    "    for n in range(ys.shape[0]): \n",
    "        Ly += (-1 * ys[n] * np.log(y_hats[n]) - (1 - ys[n]) * (np.log(1 - y_hats[n])))\n",
    "    return Ly[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db6a4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_hats(M, w):\n",
    "    \"\"\"\n",
    "        Return matrix of final estimates of each input through M and trained w.\n",
    "        M: M_map output (N, K)\n",
    "        w: Model weight between 0 and 1 (K, 1)\n",
    "    \"\"\"\n",
    "    y_hat = np.zeros(M.shape[0])\n",
    "    for n in range(M.shape[0]):\n",
    "        for k in range(M.shape[1]):\n",
    "            y_hat[n] += (M[n, k] * w[k])\n",
    "        # Clipping estimates to (0, 1)\n",
    "        y_hat[n] = 0.000001 if y_hat[n] <= 0 else y_hat[n]\n",
    "        y_hat[n] = 0.999999 if y_hat[n] >= 1 else y_hat[n]\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ec3c4",
   "metadata": {},
   "source": [
    "## <div align='center' ><font size='5'>$L_z􏰂􏰀= 􏰀\\sum_{k=1}^K|M_k^+-M_k^-|$􏰀</font></div> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7015a6f",
   "metadata": {},
   "source": [
    "In order to achieve statistical parity, we want to ensure, which can be estimated using the training data as:\n",
    "\n",
    "$$M_k^+ = M_K^-   \\space   \\space \\space \\forall k$$\n",
    "\n",
    "where\n",
    "\n",
    "$$M_k^+ =\\mathop{\\mathbb{E}}_{x \\in X^+} P(Z=k|x)= \\frac{1}{|X^+|} \\sum_{n \\in X^+} M_{nk}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c937001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_z(M_sens, M_nonsens):\n",
    "    \"\"\"\n",
    "        Loss term for fairness.\n",
    "        M_sens: M_sub_k for sensitive data (1, K)\n",
    "        M_nonsens: M_sub_k for non-sensitive data (1, K)\n",
    "    \"\"\"\n",
    "    Lz= 0.0\n",
    "    \n",
    "    for k in range(M_sens.shape[0]):\n",
    "          Lz += abs(M_sens[k] - M_nonsens[k])\n",
    "    return Lz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee933bc9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf91bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute classification\n",
    "def compute_error(y_hat, y):\n",
    "    # we will split y_hat by 0.5\n",
    "    clipped = np.clip(y_hat, 0, 1)\n",
    "    rounded = np.around(clipped)\n",
    "    return np.abs(rounded - y).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "770f1149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_error(np.array([0.4, 0.6, 0.7]), np.array([1.0, 1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "04fe2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFR():\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        label_column,\n",
    "        sensitive_column,\n",
    "        privileged_group,\n",
    "        k,\n",
    "        A_x,\n",
    "        A_y,\n",
    "        A_z\n",
    "    ):\n",
    "        self.k = k\n",
    "        self.A_x = A_x\n",
    "        self.A_y = A_y\n",
    "        self.A_z = A_z\n",
    "        \n",
    "        self.__name__ = str(k) + \" \" + str(A_x) + \" \" + str(A_y) + \" \" + str(A_z) \n",
    "        \n",
    "        self.curr_iters = 0\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.label_column = label_column\n",
    "        self.sensitive_column = sensitive_column\n",
    "        self.privileged_group = privileged_group\n",
    "        \n",
    "        train_copy = train_data.copy()\n",
    "        train_copy.drop(columns=label_column)\n",
    "        self.X = np.matrix(train_copy.to_numpy())\n",
    "        self.y = np.matrix(train_data[label_column].to_numpy()).T\n",
    "        \n",
    "        sens = train_data[sensitive_column]\n",
    "        priv_idx = np.array(np.where(sens==privileged_group))[0].flatten()\n",
    "        nonpriv_idx = np.array(np.where(sens!=privileged_group))[0].flatten()\n",
    "        self.X_plus = self.X[priv_idx,:]\n",
    "        self.y_plus = self.y[priv_idx,:]\n",
    "        self.X_minus = self.X[nonpriv_idx,:]\n",
    "        self.y_minus = self.y[nonpriv_idx,:]\n",
    "        \n",
    "    def fit(self, init_params, maxiters=100):\n",
    "        bnd = []\n",
    "        for i, k2 in enumerate(init_params):\n",
    "            if i < self.X.shape[1] * 2 or i >= self.X.shape[1] * 2 + self.k:\n",
    "                bnd.append((None, None))\n",
    "            else:\n",
    "                bnd.append((0, 1))\n",
    "        self.curr_param = init_params\n",
    "#         return\n",
    "        return optim.fmin_l_bfgs_b(self.forward, x0=init_params, epsilon=1e-5, \n",
    "                          bounds = bnd, approx_grad=True, maxfun=maxiters, maxiter=maxiters)\n",
    "        \n",
    "    def forward(self, params, return_params=False):\n",
    "        \"\"\"\n",
    "            \n",
    "        \"\"\"\n",
    "        self.curr_iters += 1\n",
    "        \n",
    "#         print(\"N_priv\")\n",
    "\n",
    "        N_priv, D = self.X_plus.shape\n",
    "        N_nonpriv, _ = self.X_minus.shape\n",
    "\n",
    "#         print(\"Extract\")\n",
    "        # Extract all params\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(params)\n",
    "\n",
    "#         print(\"Ms\")\n",
    "        M_k_p = M_map(self.X_plus, V, alpha_priv)\n",
    "        M_k_n = M_map(self.X_minus, V, alpha_nonpriv)\n",
    "\n",
    "#         print(\"Lz\")\n",
    "        Lz = L_z(M_sub_k(M_k_p), M_sub_k(M_k_n))\n",
    "\n",
    "#         print(\"Xhats\")\n",
    "        # To save time, we will just sum the two groups up\n",
    "        x_hats_p = x_hats(M_k_p, V)\n",
    "        x_hats_n = x_hats(M_k_n, V)\n",
    "#         print(\"Lx\")\n",
    "        L_x_p = L_x(self.X_plus, x_hats_p)\n",
    "        L_x_n = L_x(self.X_minus, x_hats_n)\n",
    "\n",
    "        Lx = L_x_p + L_x_n\n",
    "\n",
    "#         print(\"Yhats\")\n",
    "        y_hats_p = y_hats(M_k_p, w)\n",
    "        y_hats_n = y_hats(M_k_n, w)\n",
    "#         print(\"Ly\")\n",
    "        L_y_p = L_y(self.y_plus, y_hats_p)\n",
    "        L_y_n = L_y(self.y_minus, y_hats_n)\n",
    "\n",
    "        Ly = L_y_p + L_y_n\n",
    "\n",
    "#         print(\"Loss\", Lx, Ly, Lz)\n",
    "        loss = (self.A_x * Lx) + (self.A_y * Ly) + (self.A_z * Lz)\n",
    "\n",
    "        self.curr_param = params\n",
    "        if self.curr_iters % 50 == 0:\n",
    "            print(\n",
    "                \"model:\", self.__name__,\n",
    "                \"step:\", self.curr_iters, \n",
    "                \"loss:\", loss, \n",
    "                \"Lx:\", Lx, \n",
    "                \"Ly:\", Ly, \n",
    "                \"Lz:\", Lz)\n",
    "#             print(\"params y_hats_p, y_hats_n, M_k_p, M_k_n, loss:\",\n",
    "#                  y_hats_p, y_hats_n, M_k_p, M_k_n, loss)\n",
    "            # Predict\n",
    "            test_copy = self.test_data.copy()\n",
    "            test_copy.drop(columns=[label_column])\n",
    "\n",
    "            X_test = np.matrix(test_copy.to_numpy())\n",
    "            y_test = np.matrix(self.test_data[label_column].to_numpy()).T\n",
    "        \n",
    "            M_k_p_val = M_map(X_test, V, alpha_priv)\n",
    "            \n",
    "            y_hat = y_hats(M_k_p_val, w)\n",
    "            print(\"current error:\", compute_error(y_hat, y_test))\n",
    "\n",
    "\n",
    "        if return_params:\n",
    "            return y_hats_p, y_hats_n, M_k_p, M_k_n, loss\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "    def extract_param(self, params):\n",
    "        \n",
    "        _, D = self.X_plus.shape\n",
    "        # Extract all params\n",
    "        alpha_priv = params[:D].T\n",
    "        alpha_nonpriv = params[D:2*D].T\n",
    "\n",
    "        w = params[2*D:2*D+self.k]\n",
    "        V = np.matrix(params[(2*D)+self.k:]).reshape((self.k, D))\n",
    "        return alpha_priv, alpha_nonpriv, w, V\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(self.curr_param)\n",
    "        \n",
    "        M_k_p = M_map(X_test, V, alpha_priv)\n",
    "        \n",
    "        return y_hats(M_k_p, w)\n",
    "    \n",
    "    def predict_with_param(self, X_test, param):\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(param)\n",
    "        \n",
    "        M_k_p = M_map(X_test, V, alpha_priv)\n",
    "        \n",
    "        return y_hats(M_k_p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ce5c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(init_param, maxiters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4993fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see the model has reached minima at step 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0f11de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column=\"two_year_recid\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a4b8a81c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Vars to store results\n",
    "# cval_errs = {} # Mean validation errors\n",
    "# train_time = {} # Training time\n",
    "# # Best Model\n",
    "# best_model = None\n",
    "# # Best Validation Error\n",
    "# best_err = sys.maxsize\n",
    "\n",
    "# # Model selection \n",
    "# KS = [5]#, 10]\n",
    "# Axs = [0.00000001]#, 1, 1000000]\n",
    "# Ays = [0.01]#, 1, 1000]\n",
    "# Azs = [1000]#, 10000, 1000000]\n",
    "\n",
    "# train_data = data_train.copy()\n",
    "\n",
    "# for K in KS:\n",
    "#     init_param = np.random.uniform(size=df.shape[1] * 2 + K + df.shape[1] * K)\n",
    "#     for Ax in Axs:\n",
    "#         for Ay in Ays:    \n",
    "#             for Az in Azs:\n",
    "#                 kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "#                 y_err = []\n",
    "\n",
    "#                 start = time.time()\n",
    "\n",
    "#                 # Cross Validaiton\n",
    "#                 for train_index, val_index in kf.split(train_data):\n",
    "#                 #     print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n",
    "#                     train_copy = train_data.copy()\n",
    "#                     train_copy.drop(columns=[label_column])\n",
    "#                     train_df = train_copy.iloc[train_index]\n",
    "                    \n",
    "#                     X_val = np.matrix(train_copy.iloc[val_index].to_numpy())\n",
    "#                     y_val = np.matrix(train_data.iloc[val_index][label_column].to_numpy()).T\n",
    "\n",
    "#                     model = LFR(\n",
    "#                         train_df,\n",
    "#                         data_val,\n",
    "#                         \"two_year_recid\",\n",
    "#                         \"race\",\n",
    "#                         1,\n",
    "#                         K,\n",
    "#                         Ax,\n",
    "#                         Ay,\n",
    "#                         Az\n",
    "#                     )\n",
    "#                     model.fit(init_param, maxiters=500)\n",
    "                    \n",
    "#                     y_hat = model.predict(X_val)\n",
    "# #                     print(y_hat)\n",
    "#                     y_err.append(compute_error(y_hat, y_val))\n",
    "\n",
    "#                 end = time.time()\n",
    "\n",
    "#                 print(str(K), str(Ax), str(Ay), str(Az), \"mean val MAE:\", np.mean(y_err))\n",
    "#                 print(\"Time lapsed\", str((end - start)*1000))\n",
    "\n",
    "#                 # add to dict\n",
    "#                 cval_errs[model.__name__] = np.mean(y_err)\n",
    "#                 train_time[model.__name__] = (end - start)*1000\n",
    "#                 if np.mean(y_err) < best_err:\n",
    "#                     best_model = model\n",
    "#                     best_err = np.mean(y_err)\n",
    "#                     best_errs = y_err\n",
    "                \n",
    "# print(best_model.__name__, best_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85ccd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33d13792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f1dab3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 1e-08 0.01 1000'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "label_column = \"two_year_recid\"\n",
    "model = LFR(\n",
    "    data_train,\n",
    "    data_val,\n",
    "    label_column,\n",
    "    \"race\",\n",
    "    1,\n",
    "    K,\n",
    "    0.00000001,\n",
    "    0.01,\n",
    "    1000\n",
    ")\n",
    "model.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9453de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_param = np.random.uniform(size=df.shape[1] * 2 + K + df.shape[1] * K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2434c498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.5189393939393939\n"
     ]
    }
   ],
   "source": [
    "model.forward(init_param)\n",
    "test_copy = data_test.copy()\n",
    "X_test = np.matrix(test_copy.to_numpy())\n",
    "y_test = np.matrix(data_test[label_column].to_numpy()).T\n",
    "y_hat = model.predict(X_test)\n",
    "print(\"error:\", compute_error(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "04fe59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5 1e-08 0.01 1000 step: 50 loss: 60.047598093105705 Lx: 10903.715554306928 Ly: 3894.9959339069187 Lz: 0.021097529716880975\n",
      "current error: 0.5301775147928994\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 115.23202159462201 Lx: 10804.776794000121 Ly: 3888.1470668774 Lz: 0.07635044287808007\n",
      "current error: 0.5301775147928994\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 115.23202159456079 Lx: 10804.770672013738 Ly: 3888.1470668774 Lz: 0.07635044287808007\n",
      "current error: 0.5301775147928994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2051848/3293371957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2051848/2803411547.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, init_params, maxiters)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#         return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         return optim.fmin_l_bfgs_b(self.forward, x0=init_params, epsilon=1e-5, \n\u001b[0;32m---> 52\u001b[0;31m                           bounds = bnd, approx_grad=True, maxfun=maxiters, maxiter=maxiters)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 198\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    199\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    200\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0;32m--> 156\u001b[0;31m                                            **finite_diff_options)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0;32m--> 487\u001b[0;31m                                      use_one_sided, method)\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparsity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparsity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3-point'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2051848/2803411547.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, params, return_params)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#         print(\"Ms\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mM_k_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_priv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mM_k_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_nonpriv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#         print(\"Lz\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2051848/3408928635.py\u001b[0m in \u001b[0;36mM_map\u001b[0;34m(X, V, alpha)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0msummation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0msummation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdist_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# To avoid value error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msummation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "op = model.fit(init_param, maxiters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "test_copy = data_test.copy()\n",
    "test_copy.drop(columns=[label_column])\n",
    "\n",
    "X_test = np.matrix(test_copy.to_numpy())\n",
    "y_test = np.matrix(data_test[label_column].to_numpy()).T\n",
    "y_hat = model.predict(X_test)\n",
    "print(\"error:\", compute_error(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f210b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
