{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05cfc18",
   "metadata": {},
   "source": [
    "# # A1 Learning Fair Representations (LFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5ff6d",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d960fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.optimize as optim\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5424c1",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e1ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/compas-scores-two-years.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670edc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 06:03:42</td>\n",
       "      <td>2013-08-14 05:41:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-26 03:45:27</td>\n",
       "      <td>2013-02-05 05:36:53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-13 04:58:34</td>\n",
       "      <td>2013-04-14 07:02:04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-30 04:50:18</td>\n",
       "      <td>2013-12-01 12:28:56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-18 05:08:24</td>\n",
       "      <td>2014-02-24 12:18:30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-22 05:18:27</td>\n",
       "      <td>2013-11-24 02:59:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-31 07:13:54</td>\n",
       "      <td>2014-02-02 04:03:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-13 05:48:01</td>\n",
       "      <td>2014-01-14 07:49:46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-03-08 08:06:02</td>\n",
       "      <td>2014-03-09 12:18:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-28 12:16:41</td>\n",
       "      <td>2014-06-30 11:19:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age c_charge_degree              race          age_cat score_text  \\\n",
       "0      69               F             Other  Greater than 45        Low   \n",
       "1      34               F  African-American          25 - 45        Low   \n",
       "2      24               F  African-American     Less than 25        Low   \n",
       "5      44               M             Other          25 - 45        Low   \n",
       "6      41               F         Caucasian          25 - 45     Medium   \n",
       "...   ...             ...               ...              ...        ...   \n",
       "7209   23               F  African-American     Less than 25     Medium   \n",
       "7210   23               F  African-American     Less than 25        Low   \n",
       "7211   57               F             Other  Greater than 45        Low   \n",
       "7212   33               M  African-American          25 - 45        Low   \n",
       "7213   23               F          Hispanic     Less than 25        Low   \n",
       "\n",
       "         sex  priors_count  days_b_screening_arrest  decile_score  is_recid  \\\n",
       "0       Male             0                     -1.0             1         0   \n",
       "1       Male             0                     -1.0             3         1   \n",
       "2       Male             4                     -1.0             4         1   \n",
       "5       Male             0                      0.0             1         0   \n",
       "6       Male            14                     -1.0             6         1   \n",
       "...      ...           ...                      ...           ...       ...   \n",
       "7209    Male             0                     -1.0             7         0   \n",
       "7210    Male             0                     -1.0             3         0   \n",
       "7211    Male             0                     -1.0             1         0   \n",
       "7212  Female             3                     -1.0             2         0   \n",
       "7213  Female             2                     -2.0             4         1   \n",
       "\n",
       "                c_jail_in           c_jail_out  two_year_recid  \n",
       "0     2013-08-13 06:03:42  2013-08-14 05:41:20               0  \n",
       "1     2013-01-26 03:45:27  2013-02-05 05:36:53               1  \n",
       "2     2013-04-13 04:58:34  2013-04-14 07:02:04               1  \n",
       "5     2013-11-30 04:50:18  2013-12-01 12:28:56               0  \n",
       "6     2014-02-18 05:08:24  2014-02-24 12:18:30               1  \n",
       "...                   ...                  ...             ...  \n",
       "7209  2013-11-22 05:18:27  2013-11-24 02:59:20               0  \n",
       "7210  2014-01-31 07:13:54  2014-02-02 04:03:52               0  \n",
       "7211  2014-01-13 05:48:01  2014-01-14 07:49:46               0  \n",
       "7212  2014-03-08 08:06:02  2014-03-09 12:18:04               0  \n",
       "7213  2014-06-28 12:16:41  2014-06-30 11:19:23               1  \n",
       "\n",
       "[6172 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw[['age', 'c_charge_degree', 'race', 'age_cat',\n",
    "                    'score_text', 'sex', 'priors_count', 'days_b_screening_arrest',\n",
    "                    'decile_score', 'is_recid', 'c_jail_in',\n",
    "                    'c_jail_out', 'two_year_recid']]\\\n",
    "                    .query('days_b_screening_arrest <= 30')\\\n",
    "                    .query('days_b_screening_arrest >= -30')\\\n",
    "                    .query('is_recid != -1')\\\n",
    "                    .query('c_charge_degree != \"O\"')\\\n",
    "                    .query('score_text != \"N/A\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35151005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 13)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unrelated columns\n",
    "df = df[(df.race=='African-American') | (df.race=='Caucasian')]\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9deb71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "dt1 = list(map(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date(), df['c_jail_out']))\n",
    "dt2 = list(map(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S').date(), df['c_jail_in']))\n",
    "\n",
    "len_stay = [(a-b).days for a,b in zip(dt1,dt2)]\n",
    "\n",
    "df['length_of_stay'] = len_stay\n",
    "df = df.drop(['c_jail_out', 'c_jail_in'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17e6c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns so y is the last column\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[:-2] + cols[-1:] + cols[-2:-1]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d64aa9",
   "metadata": {},
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b81f73a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical: ['c_charge_degree', 'race', 'age_cat', 'score_text', 'sex']\n",
      "numerical: ['age', 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid', 'length_of_stay']\n"
     ]
    }
   ],
   "source": [
    "label_column = ['two_year_recid']\n",
    "catogory_features = []\n",
    "numeric_features = []\n",
    "\n",
    "for col in df.columns.values:\n",
    "    if col in label_column:\n",
    "        continue\n",
    "    elif df[col].dtypes in ('int64', 'float64') :\n",
    "        numeric_features += [col]\n",
    "    else:\n",
    "        catogory_features += [col]\n",
    "        \n",
    "print(\"categorical:\", catogory_features)\n",
    "print(\"numerical:\", numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59453091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we replace categorical columns with numeric values\n",
    "df_num = df.copy()\n",
    "feat2name = {}\n",
    "encoders = {}\n",
    "\n",
    "# Use Label Encoder for categorical columns (including target column)\n",
    "for feature in catogory_features:\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df_num[feature])\n",
    "    \n",
    "    df_num[feature] = encoder.transform(df_num[feature])\n",
    "    \n",
    "    feat2name[feature] = encoder.classes_\n",
    "    encoders[feature] = encoder\n",
    "\n",
    "# Use MinMaxScaler for numerical columns     \n",
    "for feature in numeric_features:\n",
    "    val = df_num[feature].values[:, np.newaxis]\n",
    "    mms = MinMaxScaler().fit(val)\n",
    "    df_num[feature] = mms.transform(val)\n",
    "    encoders[feature] = mms\n",
    "    \n",
    "df_num = df_num.astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4ac76ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African-American', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['race'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "205f1c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 12)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a155765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.338710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  c_charge_degree  race  age_cat  score_text  sex  priors_count  \\\n",
       "1   0.258065              0.0   0.0      0.0         1.0  1.0      0.000000   \n",
       "2   0.096774              0.0   0.0      2.0         1.0  1.0      0.105263   \n",
       "6   0.370968              0.0   1.0      0.0         2.0  1.0      0.368421   \n",
       "8   0.338710              1.0   1.0      0.0         1.0  0.0      0.000000   \n",
       "10  0.145161              0.0   1.0      0.0         1.0  1.0      0.000000   \n",
       "\n",
       "    days_b_screening_arrest  decile_score  is_recid  length_of_stay  \\\n",
       "1                  0.483333      0.222222       1.0         0.01250   \n",
       "2                  0.483333      0.333333       1.0         0.00125   \n",
       "6                  0.483333      0.555556       1.0         0.00750   \n",
       "8                  0.483333      0.000000       0.0         0.00375   \n",
       "10                 0.483333      0.333333       0.0         0.00125   \n",
       "\n",
       "    two_year_recid  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "6              1.0  \n",
       "8              0.0  \n",
       "10             0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9bf0bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African-American', 'Caucasian'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['race'].classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c931b1",
   "metadata": {},
   "source": [
    "## Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "603597ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(df_num, test_size=0.2)\n",
    "data_train, data_val= train_test_split(data_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c911325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will define some of the constants and functions mentioned in the paper\n",
    "N = df.shape[0]  # number of samples in X\n",
    "D = df.shape[1]  # Dimension of x vector\n",
    "K = 10  # Number of prototypes represented in Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2271d8",
   "metadata": {},
   "source": [
    "## LFR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9546a",
   "metadata": {},
   "source": [
    "The goal of LFR is to learn a good prototype set $Z$ such that:\n",
    "1. the mapping from $X_0$ to $Z$ satisfies statistical parity;\n",
    "2. the mapping to $Z$-space retains information in $X$ (except for membership in the protected set); and\n",
    "3. the induced mapping from $X$ to $Y$ (by first mapping each $x$ probabilistically to $Z$-space, and then mapping $Z$ to $Y$) is close to f.\n",
    "\n",
    "Each of these aims corresponds to a term in the objective function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef07e6a",
   "metadata": {},
   "source": [
    "## (1) Define "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8011e8f",
   "metadata": {},
   "source": [
    "We define $M_{nk}$ as the probability that $x_n$ maps to $v_k$.\n",
    "\n",
    "So,\n",
    "$$M_{nk} = P(Z=k|x_n) \\space\\space \n",
    "=\\frac{exp(-d(x_n, v_k))}{\\sum_{k=1}^K exp(-d(x_n, v_k))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04ce34",
   "metadata": {},
   "source": [
    "###  Calculates the euclidean distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496429af",
   "metadata": {},
   "source": [
    "$$d(x_n, v_k, \\alpha) = \\sum^D_{d=1} \\alpha_d (x_{nd} - v_{kd})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f1a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d(x1, x2, alpha):\n",
    "    \"\"\"\n",
    "        Calculates the euclidean distance between x1 and x2 with feature weights alpha\n",
    "        x1: First vector in X vector space (D, 1)\n",
    "        x2: Second vector in X vector space (D, 1)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    x1 = n###  Calculates the euclidean distance$d(x_n, v_k, \\alpha) = \\sum^D_{d=1} \\alpha_d (x_{nd} - v_{kd})^2$p.matrix(x1)\n",
    "    x2 = np.matrix(## Spliting Datax2)\n",
    "    alpha = np.matrix(alpha)\n",
    "#     print(x1, x2, alpha)\n",
    "#     print(np.multiply(np.multiply((x1 - x2), (x1 - x2)),alpha))\n",
    "    return sum(np.multiply(np.multiply((x1 - x2), (x1 - x2)), alpha))[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c52fd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test \n",
    "d(np.matrix([1,2,3]).T, np.matrix([0,0,0]).T, np.matrix([1,1,2]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b74ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time for later, we will cache the distance map between all inputs X_i \n",
    "# and current prototypes V_k\n",
    "def d_map(X, V, alpha):\n",
    "    \"\"\"\n",
    "        Returns a 2D matrix with shape (N, K) with each cell (i, j) \n",
    "            distance from input x_i to prototype v_j with weighted features\n",
    "        X: Input matrix (N, D)\n",
    "        V: Prototype matrix (K, D)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    distance_map = np.zeros((X.shape[0], V.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            distance_map[i, j] = d(X[i, :], V[j, :], alpha)\n",
    "            \n",
    "    return distance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e714ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162.,   8.],\n",
       "       [ 98.,   0.],\n",
       "       [ 32.,  18.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "d_map(np.matrix([[1,2],[3,4],[6,7]]), np.matrix([[10,2],[3,40]]), np.matrix([[1.0],[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5eaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_nk(X, n, V, k, alpha, dist_map, summation):\n",
    "    \"\"\"\n",
    "        Calculate the prob of X_n is classified to kth prototype using softmax\n",
    "        X: Input matrix (N, D)\n",
    "        n: the nth input to calculate the prob for\n",
    "        V: prototype matrix (K, D)\n",
    "        k: the kth prototype to classify for\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    p = 0\n",
    "    exponent = np.exp(-1 * dist_map[n, k])\n",
    "    p = exponent / summation\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3534b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save time later, we will cache the probs of each x mapped to k\n",
    "def M_map(X, V, alpha):\n",
    "    \"\"\"\n",
    "        Return the prob of each x mapping to a prototype v (N, K)\n",
    "        X: Input matrix (N, D)\n",
    "        V: Prototype matrix (K, D)\n",
    "        alpha: weight vector for each of the features (D, 1)\n",
    "    \"\"\"\n",
    "    M = np.zeros((X.shape[0], V.shape[0]))\n",
    "    \n",
    "    dist_map = d_map(X, V, alpha)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(V.shape[0]):\n",
    "            summation = 0\n",
    "            for k_idx in range(V.shape[0]):\n",
    "                summation += np.exp(-1 * dist_map[i, k_idx])\n",
    "            # To avoid value error\n",
    "            if (summation == 0): \n",
    "                summation = 0.000001\n",
    "            M[i, j] = M_nk(X, i, V, j, alpha, dist_map, summation)\n",
    "    return M\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f616f0",
   "metadata": {},
   "source": [
    "$$M_k =\\mathop{\\mathbb{E}}_{x \\in X} P(Z=k|x)= \\frac{1}{|X|} \\sum_{n \\in X} M_{nk}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "574d24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_sub_k(M_sub_map):\n",
    "    \"\"\"\n",
    "        Calculate estimated prob of mapping to k for a subset M_map. (K,)\n",
    "        M_sub_map: prob of each x mapping to a prototype (N0, K)\n",
    "    \"\"\"\n",
    "    Ms = np.zeros(M_sub_map.shape[1])\n",
    "    \n",
    "    for k in range(M_sub_map.shape[1]):\n",
    "        for n in range(M_sub_map.shape[0]):\n",
    "            Ms[k] += M_sub_map[n, k]\n",
    "        Ms[k] /= M_sub_map.shape[0]\n",
    "    return Ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e70a9",
   "metadata": {},
   "source": [
    "## (2) Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37cc00",
   "metadata": {},
   "source": [
    "## \n",
    "<h1 align = \"center\">$Total \\space Loss = A_x * L_x + A_y * L_y + A_z * L_z 􏰂􏰀􏰀$<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657df402",
   "metadata": {},
   "source": [
    "where $A_x, A_y, A_z$ are hyper-parameters governing the trade-off between the system desiderata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6042fb",
   "metadata": {},
   "source": [
    "## <div align='center' ><font size='5'>$L_x = \\sum_{n=1}^N (x_n - \\hat{x}_n)^2$</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3121c",
   "metadata": {},
   "source": [
    "where $$\\hat{x}_n = \\sum^K_{k=1}M_{nk}v_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df127ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_x(X, x_ha## (2) Objective Function## $L_x = \\sum_{n=1}^N (x_n - \\hat{x}_n)^2$ts):\n",
    "    \"\"\"\n",
    "        Loss term for goodness of the prototype.\n",
    "        X: input matrix (N, D)\n",
    "        x_hats: x estimates (N, D)\n",
    "    \"\"\"\n",
    "    Lx = 0\n",
    "    for n in range(X.shape[0]):\n",
    "        for d in range(X.shape[1]):\n",
    "            Lx += (X[n, d] - x_hats[n, d]) * (X[n, d] - x_hats[n, d])\n",
    "    return Lx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d59851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_hats(M, V):\n",
    "    \"\"\"\n",
    "        Return a matrix of reconstructed x through M \n",
    "            using each of the prototypes. (N, D)\n",
    "        M: M_map output (N, K)\n",
    "        V: Prototy$$\\hat{x}_n = \\sum^K_{k=1}M_{nk}v_k$$pe matrix (K, D)\n",
    "    \"\"\"\n",
    "    return np.matmul(M, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8aeb49",
   "metadata": {},
   "source": [
    "## <div align='center' ><font size='5'>$L_y = \\sum_{n=1}^N -y_n log \\hat{y}_n - (1-y_n)log(1- \\hat{y}_n)$</font></div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499a058",
   "metadata": {},
   "source": [
    "$$\\hat{y}_n = \\sum^K_{k=1} M_{nk}w_k \\\\\n",
    "0< w_k <1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20c28526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_y(ys, y_hats):\n",
    "    \"\"\"\n",
    "        Loss term for accuracy of the model\n",
    "        ys: Gound-truth ## $L_y = \\sum_{n=1}^N -y_n log \\hat{y}_n - (1-y_n)log(1- \\hat{y}_n)$label of X (N, 1)\n",
    "        y_hats: y estimates (N, 1)\n",
    "    \"\"\"\n",
    "    Ly = 0\n",
    "    for n in range(ys.shape[0]): \n",
    "        Ly += (-1 * ys[n] * np.log(y_hats[n]) - (1 - ys[n]) * (np.log(1 - y_hats[n])))\n",
    "    return Ly[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db6a4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_hats(M, w):\n",
    "    \"\"\"\n",
    "        Return matrix of final estimates of each input through M and trained w.\n",
    "        M: M_map output (N, K)\n",
    "        w: Model weight between 0 and 1 (K, 1)\n",
    "    \"\"\"\n",
    "    y_hat = np.zeros(M.shape[0])\n",
    "    for n in range(M.shape[0]):\n",
    "        for k in range(M.shape[1]):\n",
    "            y_hat[n] += (M[n, k] * w[k])\n",
    "        # Clipping estimates to (0, 1)\n",
    "        y_hat[n] = 0.000001 if y_hat[n] <= 0 else y_hat[n]\n",
    "        y_hat[n] = 0.999999 if y_hat[n] >= 1 else y_hat[n]\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ec3c4",
   "metadata": {},
   "source": [
    "## <div align='center' ><font size='5'>$L_z􏰂􏰀= 􏰀\\sum_{k=1}^K|M_k^+-M_k^-|$􏰀</font></div> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7015a6f",
   "metadata": {},
   "source": [
    "In order to achieve statistical parity, we want to ensure, which can be estimated using the training data as:\n",
    "\n",
    "$$M_k^+ = M_K^-   \\space   \\space \\space \\forall k$$\n",
    "\n",
    "where\n",
    "\n",
    "$$M_k^+ =\\mathop{\\mathbb{E}}_{x \\in X^+} P(Z=k|x)= \\frac{1}{|X^+|} \\sum_{n \\in X^+} M_{nk}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c937001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_z(M_sens, M_nonsens):\n",
    "    \"\"\"\n",
    "        Loss term for fairness.\n",
    "        M_sens: M_sub_k for sensitive data (1, K)\n",
    "        M_nonsens: M_sub_k for non-sensitive data (1, K)\n",
    "    \"\"\"\n",
    "    Lz= 0.0\n",
    "    \n",
    "    for k in range(M_sens.shape[0]):\n",
    "          Lz += abs(M_sens[k] - M_nonsens[k])\n",
    "    return Lz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee933bc9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04fe2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFR():\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data,\n",
    "        label_column,\n",
    "        sensitive_column,\n",
    "        privileged_group,\n",
    "        k,\n",
    "        A_x,\n",
    "        A_y,\n",
    "        A_z\n",
    "    ):\n",
    "        self.k = k\n",
    "        self.A_x = A_x\n",
    "        self.A_y = A_y\n",
    "        self.A_z = A_z\n",
    "        \n",
    "        self.__name__ = str(k) + \" \" + str(A_x) + \" \" + str(A_y) + \" \" + str(A_z) \n",
    "        \n",
    "        self.curr_iters = 0\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.label_column = label_column\n",
    "        self.sensitive_column = sensitive_column\n",
    "        self.privileged_group = privileged_group\n",
    "        \n",
    "        train_copy = train_data.copy()\n",
    "        train_copy.drop(columns=label_column)\n",
    "        self.X = np.matrix(train_copy.to_numpy())\n",
    "        self.y = np.matrix(train_data[label_column].to_numpy()).T\n",
    "        \n",
    "        sens = train_data[sensitive_column]\n",
    "        priv_idx = np.array(np.where(sens==privileged_group))[0].flatten()\n",
    "        nonpriv_idx = np.array(np.where(sens!=privileged_group))[0].flatten()\n",
    "        self.X_plus = self.X[priv_idx,:]\n",
    "        self.y_plus = self.y[priv_idx,:]\n",
    "        self.X_minus = self.X[nonpriv_idx,:]\n",
    "        self.y_minus = self.y[nonpriv_idx,:]\n",
    "        \n",
    "    def fit(self, init_params, maxiters=100):\n",
    "        bnd = []\n",
    "        for i, k2 in enumerate(init_params):\n",
    "            if i < self.X.shape[1] * 2 or i >= self.X.shape[1] * 2 + self.k:\n",
    "                bnd.append((None, None))\n",
    "            else:\n",
    "                bnd.append((0, 1))\n",
    "        self.curr_param = init_params\n",
    "#         return\n",
    "        return optim.fmin_l_bfgs_b(self.forward, x0=init_params, epsilon=1e-5, \n",
    "                          bounds = bnd, approx_grad=True, maxfun=maxiters, maxiter=maxiters)\n",
    "        \n",
    "    def forward(self, params, return_params=False):\n",
    "        \"\"\"\n",
    "            \n",
    "        \"\"\"\n",
    "        self.curr_iters += 1\n",
    "        \n",
    "#         print(\"N_priv\")\n",
    "\n",
    "        N_priv, D = self.X_plus.shape\n",
    "        N_nonpriv, _ = self.X_minus.shape\n",
    "\n",
    "#         print(\"Extract\")\n",
    "        # Extract all params\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(params)\n",
    "\n",
    "#         print(\"Ms\")\n",
    "        M_k_p = M_map(self.X_plus, V, alpha_priv)\n",
    "        M_k_n = M_map(self.X_minus, V, alpha_nonpriv)\n",
    "\n",
    "#         print(\"Lz\")\n",
    "        Lz = L_z(M_sub_k(M_k_p), M_sub_k(M_k_n))\n",
    "\n",
    "#         print(\"Xhats\")\n",
    "        # To save time, we will just sum the two groups up\n",
    "        x_hats_p = x_hats(M_k_p, V)\n",
    "        x_hats_n = x_hats(M_k_n, V)\n",
    "#         print(\"Lx\")\n",
    "        L_x_p = L_x(self.X_plus, x_hats_p)\n",
    "        L_x_n = L_x(self.X_minus, x_hats_n)\n",
    "\n",
    "        Lx = L_x_p + L_x_n\n",
    "\n",
    "#         print(\"Yhats\")\n",
    "        y_hats_p = y_hats(M_k_p, w)\n",
    "        y_hats_n = y_hats(M_k_n, w)\n",
    "#         print(\"Ly\")\n",
    "        L_y_p = L_y(self.y_plus, y_hats_p)\n",
    "        L_y_n = L_y(self.y_minus, y_hats_n)\n",
    "\n",
    "        Ly = L_y_p + L_y_n\n",
    "\n",
    "#         print(\"Loss\", Lx, Ly, Lz)\n",
    "        loss = (self.A_x * Lx) + (self.A_y * Ly) + (self.A_z * Lz)\n",
    "\n",
    "        if self.curr_iters % 50 == 0:\n",
    "            print(\n",
    "                \"model:\", self.__name__,\n",
    "                \"step:\", self.curr_iters, \n",
    "                \"loss:\", loss, \n",
    "                \"Lx:\", Lx, \n",
    "                \"Ly:\", Ly, \n",
    "                \"Lz:\", Lz)\n",
    "#             print(\"params y_hats_p, y_hats_n, M_k_p, M_k_n, loss:\",\n",
    "#                  y_hats_p, y_hats_n, M_k_p, M_k_n, loss)\n",
    "\n",
    "        self.curr_param = params\n",
    "\n",
    "        if return_params:\n",
    "            return y_hats_p, y_hats_n, M_k_p, M_k_n, loss\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "    def extract_param(self, params):\n",
    "        \n",
    "        _, D = self.X_plus.shape\n",
    "        # Extract all params\n",
    "        alpha_priv = params[:D].T\n",
    "        alpha_nonpriv = params[D:2*D].T\n",
    "\n",
    "        w = params[2*D:2*D+self.k]\n",
    "        V = np.matrix(params[(2*D)+self.k:]).reshape((self.k, D))\n",
    "        return alpha_priv, alpha_nonpriv, w, V\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        alpha_priv, alpha_nonpriv, w, V = self.extract_param(self.curr_param)\n",
    "        \n",
    "        M_k_p = M_map(X_test, V, alpha_priv)\n",
    "        \n",
    "        return y_hats(M_k_p, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce5c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(init_param, maxiters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4993fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see the model has reached minima at step 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f11de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2622</td>\n",
       "      <td>2560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3754</td>\n",
       "      <td>3622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5064</td>\n",
       "      <td>5005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7044</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4110</td>\n",
       "      <td>4006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2249</td>\n",
       "      <td>2146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1838</td>\n",
       "      <td>2039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2781</td>\n",
       "      <td>2627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4529</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3513</td>\n",
       "      <td>3380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3377 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  c_charge_degree  race  age_cat  score_text  sex  priors_count  \\\n",
       "2511   27                1     0        0           2    1             2   \n",
       "5551   37                1     0        0           1    1             3   \n",
       "5863   26                1     0        0           1    0             1   \n",
       "4487   27                0     1        0           0    1             7   \n",
       "7044   63                0     0        1           1    1             1   \n",
       "...   ...              ...   ...      ...         ...  ...           ...   \n",
       "1184   32                0     0        0           1    0             6   \n",
       "230    23                0     0        2           0    1             2   \n",
       "5130   43                1     1        0           1    1             1   \n",
       "4915   26                1     0        0           1    1             3   \n",
       "3283   21                1     1        2           1    1             1   \n",
       "\n",
       "      days_b_screening_arrest  decile_score  is_recid  c_jail_in  c_jail_out  \n",
       "2511                     -1.0             5         1       2622        2560  \n",
       "5551                     -1.0             3         0        388        1333  \n",
       "5863                    -23.0             4         0       3754        3622  \n",
       "4487                     -1.0             8         1       5064        5005  \n",
       "7044                     -1.0             1         0       4110        4006  \n",
       "...                       ...           ...       ...        ...         ...  \n",
       "1184                     -1.0             4         1       2249        2146  \n",
       "230                      -1.0             9         0       1838        2039  \n",
       "5130                     -1.0             1         0       2781        2627  \n",
       "4915                      0.0             4         1       4529        4466  \n",
       "3283                     -1.0             4         1       3513        3380  \n",
       "\n",
       "[3377 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_column=\"two_year_recid\"\n",
    "train_data.drop(columns=[label_column])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a4b8a81c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5 1e-08 0.01 1000 step: 50 loss: 29.58335302831514 Lx: 9536.690644667306 Ly: 1907.6846392609884 Lz: 0.01050641126879881\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 24.881879028576947 Lx: 9514.497383643346 Ly: 1900.4858870530031 Lz: 0.0058769250130730755\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 24.88187902853432 Lx: 9514.493121271486 Ly: 1900.4858870530031 Lz: 0.0058769250130730755\n",
      "model: 5 1e-08 0.01 1000 step: 200 loss: 75.7982311565828 Lx: 9493.809596163092 Ly: 1903.1690304751385 Lz: 0.05676644591373545\n",
      "model: 5 1e-08 0.01 1000 step: 250 loss: 75.79823115655486 Lx: 9493.806803251275 Ly: 1903.1690304751385 Lz: 0.05676644591373545\n",
      "model: 5 1e-08 0.01 1000 step: 300 loss: 21.018681707390613 Lx: 9512.131211597705 Ly: 1900.1797179517605 Lz: 0.002016789406560887\n",
      "model: 5 1e-08 0.01 1000 step: 350 loss: 21.018700138916245 Lx: 9512.13343267958 Ly: 1900.181561102103 Lz: 0.002016789406560887\n",
      "model: 5 1e-08 0.01 1000 step: 400 loss: 300.5665248975969 Lx: 9425.99612983856 Ly: 1933.0082907759736 Lz: 0.2812363477298758\n",
      "model: 5 1e-08 0.01 1000 step: 450 loss: 300.56652489761973 Lx: 9425.998417707478 Ly: 1933.0082907759736 Lz: 0.2812363477298758\n",
      "model: 5 1e-08 0.01 1000 step: 500 loss: 32.044915085844366 Lx: 9509.216816018929 Ly: 1900.8483359090787 Lz: 0.013036336634585421\n",
      "model: 5 1e-08 0.01 1000 step: 550 loss: 20.61522257409924 Lx: 9511.847974337968 Ly: 1900.2288325276418 Lz: 0.0016128391303430745\n",
      "model: 5 1e-08 0.01 1000 step: 600 loss: 20.615222574056382 Lx: 9511.843688723893 Ly: 1900.2288325276418 Lz: 0.0016128391303430745\n",
      "model: 5 1e-08 0.01 1000 step: 50 loss: 29.408037951984383 Lx: 9549.691883329371 Ly: 1911.8434494619876 Lz: 0.01028950796044567\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 26.074090438326184 Lx: 9529.786707943513 Ly: 1903.9262369871494 Lz: 0.0070347327705876095\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 26.0740904382842 Lx: 9529.782509360766 Ly: 1903.9262369871494 Lz: 0.0070347327705876095\n",
      "model: 5 1e-08 0.01 1000 step: 200 loss: 59.36254708028413 Lx: 9511.653274004839 Ly: 1903.9532194008077 Lz: 0.04032291976974331\n",
      "model: 5 1e-08 0.01 1000 step: 250 loss: 59.36254708025463 Lx: 9511.650324255726 Ly: 1903.9532194008077 Lz: 0.04032291976974331\n",
      "model: 5 1e-08 0.01 1000 step: 300 loss: 21.674612955707204 Lx: 9526.87594607322 Ly: 1903.3449981121487 Lz: 0.0026410677058262555\n",
      "model: 5 1e-08 0.01 1000 step: 350 loss: 21.674631984194175 Lx: 9526.878268351635 Ly: 1903.3469009585235 Lz: 0.0026410677058262555\n",
      "model: 5 1e-08 0.01 1000 step: 400 loss: 86.12375203457798 Lx: 9488.71220157054 Ly: 1908.7054461284333 Lz: 0.06703660268617162\n",
      "model: 5 1e-08 0.01 1000 step: 450 loss: 86.12375203459325 Lx: 9488.713730261032 Ly: 1908.7054461284333 Lz: 0.06703660268617162\n",
      "model: 5 1e-08 0.01 1000 step: 500 loss: 25.921453320779094 Lx: 9526.007482722416 Ly: 1903.6174775892882 Lz: 0.006885183284811386\n",
      "model: 5 1e-08 0.01 1000 step: 550 loss: 20.205496846951934 Lx: 9526.788673884932 Ly: 1903.387445914445 Lz: 0.0011715271199207455\n",
      "model: 5 1e-08 0.01 1000 step: 600 loss: 20.205496846909714 Lx: 9526.784451769323 Ly: 1903.387445914445 Lz: 0.0011715271199207455\n",
      "model: 5 1e-08 0.01 1000 step: 50 loss: 29.310803159698416 Lx: 9528.266512308324 Ly: 1918.7030837796876 Lz: 0.010123677039236417\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 27.265846306761905 Lx: 9508.891660438738 Ly: 1910.0765676734823 Lz: 0.008164985541110475\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 27.265846306719393 Lx: 9508.887409336397 Ly: 1910.0765676734823 Lz: 0.008164985541110475\n",
      "model: 5 1e-08 0.01 1000 step: 200 loss: 71.07819034070518 Lx: 9489.208907005157 Ly: 1900.374794359076 Lz: 0.05207434750502535\n",
      "model: 5 1e-08 0.01 1000 step: 250 loss: 71.07819034067288 Lx: 9489.205676201715 Ly: 1900.374794359076 Lz: 0.05207434750502535\n",
      "model: 5 1e-08 0.01 1000 step: 300 loss: 27.18375351686899 Lx: 9504.595457876987 Ly: 1908.6332888026795 Lz: 0.008097325582887616\n",
      "model: 5 1e-08 0.01 1000 step: 350 loss: 27.183773110239372 Lx: 9504.597618817475 Ly: 1908.635248137557 Lz: 0.008097325582887616\n",
      "model: 5 1e-08 0.01 1000 step: 400 loss: 34.33587408392228 Lx: 9516.375302452449 Ly: 1909.9910500448016 Lz: 0.015235868419721244\n",
      "model: 5 1e-08 0.01 1000 step: 450 loss: 34.33587408393566 Lx: 9516.376640092138 Ly: 1909.9910500448016 Lz: 0.015235868419721244\n",
      "model: 5 1e-08 0.01 1000 step: 500 loss: 27.18617168180768 Lx: 9507.293035844239 Ly: 1909.0686156558686 Lz: 0.008095390452318635\n",
      "model: 5 1e-08 0.01 1000 step: 550 loss: 25.696143921429307 Lx: 9505.85778819684 Ly: 1908.8476806226715 Lz: 0.006607572056624711\n",
      "model: 5 1e-08 0.01 1000 step: 600 loss: 25.696143921386646 Lx: 9505.853522005147 Ly: 1908.8476806226715 Lz: 0.006607572056624711\n",
      "model: 5 1e-08 0.01 1000 step: 50 loss: 29.273897635882086 Lx: 9538.477118430332 Ly: 1918.5933543200085 Lz: 0.010087868707910813\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 27.351244541376193 Lx: 9519.286012888359 Ly: 1910.343145390158 Lz: 0.008247717894614481\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 27.3512445413331 Lx: 9519.281703520894 Ly: 1910.343145390158 Lz: 0.008247717894614481\n",
      "model: 5 1e-08 0.01 1000 step: 200 loss: 71.29080688171301 Lx: 9498.41547928246 Ly: 1900.758177069655 Lz: 0.05228313012686167\n",
      "model: 5 1e-08 0.01 1000 step: 250 loss: 71.29080688168065 Lx: 9498.412242194983 Ly: 1900.758177069655 Lz: 0.05228313012686167\n",
      "model: 5 1e-08 0.01 1000 step: 300 loss: 27.061521688915633 Lx: 9514.786084986588 Ly: 1908.9005796239426 Lz: 0.007972420744815356\n",
      "model: 5 1e-08 0.01 1000 step: 350 loss: 27.06154133890122 Lx: 9514.788280081986 Ly: 1908.9025446203063 Lz: 0.007972420744815356\n",
      "model: 5 1e-08 0.01 1000 step: 400 loss: 34.61052512328194 Lx: 9526.388648860431 Ly: 1910.1236951128926 Lz: 0.015509192908266523\n",
      "model: 5 1e-08 0.01 1000 step: 450 loss: 34.610525123295425 Lx: 9526.389997595306 Ly: 1910.1236951128926 Lz: 0.015509192908266523\n",
      "model: 5 1e-08 0.01 1000 step: 500 loss: 27.379662330827536 Lx: 9517.396557334036 Ly: 1909.2816517126325 Lz: 0.008286750639735635\n",
      "model: 5 1e-08 0.01 1000 step: 550 loss: 25.65616710931364 Lx: 9515.869532356473 Ly: 1909.0676522209892 Lz: 0.0065653954284084215\n",
      "model: 5 1e-08 0.01 1000 step: 600 loss: 25.656167109270378 Lx: 9515.86520637403 Ly: 1909.0676522209892 Lz: 0.0065653954284084215\n",
      "model: 5 1e-08 0.01 1000 step: 50 loss: 29.551633373451068 Lx: 9565.159637938934 Ly: 1928.992428084804 Lz: 0.01026161344100665\n",
      "model: 5 1e-08 0.01 1000 step: 100 loss: 26.3255032850492 Lx: 9544.435621835126 Ly: 1920.386681968661 Lz: 0.007121541021006372\n",
      "model: 5 1e-08 0.01 1000 step: 150 loss: 26.32550328500601 Lx: 9544.431302783209 Ly: 1920.386681968661 Lz: 0.007121541021006372\n",
      "model: 5 1e-08 0.01 1000 step: 200 loss: 60.55513115834739 Lx: 9525.942282959615 Ly: 1917.732290097283 Lz: 0.04137771299795173\n",
      "model: 5 1e-08 0.01 1000 step: 250 loss: 60.555131158318005 Lx: 9525.939343613816 Ly: 1917.732290097283 Lz: 0.04137771299795173\n",
      "model: 5 1e-08 0.01 1000 step: 300 loss: 21.634544009540832 Lx: 9541.476242797224 Ly: 1919.2712630472545 Lz: 0.002441735964305858\n",
      "model: 5 1e-08 0.01 1000 step: 350 loss: 21.634565670724633 Lx: 9541.478458400159 Ly: 1919.2734291634192 Lz: 0.002441735964305858\n",
      "model: 5 1e-08 0.01 1000 step: 400 loss: 83.6800692684045 Lx: 9506.590713021375 Ly: 1920.6388491020375 Lz: 0.06447358571147699\n",
      "model: 5 1e-08 0.01 1000 step: 450 loss: 83.68006926841943 Lx: 9506.592206502817 Ly: 1920.6388491020375 Lz: 0.06447358571147699\n",
      "model: 5 1e-08 0.01 1000 step: 500 loss: 25.849037135218328 Lx: 9540.644433201334 Ly: 1918.9846586153717 Lz: 0.0066590951426202805\n",
      "model: 5 1e-08 0.01 1000 step: 550 loss: 20.143619814661076 Lx: 9541.388795687151 Ly: 1919.1870695002399 Lz: 0.0009516537057707164\n",
      "model: 5 1e-08 0.01 1000 step: 600 loss: 20.14361981461764 Lx: 9541.384452226399 Ly: 1919.1870695002399 Lz: 0.0009516537057707164\n",
      "model: 5 1e-08 0.01 1000 step: 650 loss: 23.543584619810474 Lx: 9540.973496507242 Ly: 1919.0369513307128 Lz: 0.004353119696768382\n",
      "model: 5 1e-08 0.01 1000 step: 700 loss: 23.543584619778727 Lx: 9540.970321844103 Ly: 1919.0369513307128 Lz: 0.004353119696768382\n",
      "model: 5 1e-08 0.01 1000 step: 750 loss: 20.311243259289032 Lx: 9541.34508796614 Ly: 1919.1579081021484 Lz: 0.0011195687648166697\n",
      "model: 5 1e-08 0.01 1000 step: 800 loss: 20.311264837273715 Lx: 9541.347307880167 Ly: 1919.1600658983964 Lz: 0.0011195687648166697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1e-08 0.01 1000 mean val MAE: 0.4920549209306736\n",
      "Time lapsed 2714072.019100189\n",
      "5 1e-08 0.01 1000 0.4920549209306736\n"
     ]
    }
   ],
   "source": [
    "# Compute MAE\n",
    "def compute_error(y_hat, y):\n",
    "    # mean absolute error\n",
    "    return np.abs(y_hat - y).mean()\n",
    "\n",
    "# Vars to store results\n",
    "cval_errs = {} # Mean validation errors\n",
    "train_time = {} # Training time\n",
    "# Best Model\n",
    "best_model = None\n",
    "# Best Validation Error\n",
    "best_err = sys.maxsize\n",
    "\n",
    "# Model selection \n",
    "KS = [5]#, 10]\n",
    "Axs = [0.00000001]#, 1, 1000000]\n",
    "Ays = [0.01]#, 1, 1000]\n",
    "Azs = [1000]#, 10000, 1000000]\n",
    "\n",
    "train_data = data_train.copy()\n",
    "\n",
    "for K in KS:\n",
    "    init_param = np.random.uniform(size=df.shape[1] * 2 + K + df.shape[1] * K)\n",
    "    for Ax in Axs:\n",
    "        for Ay in Ays:    \n",
    "            for Az in Azs:\n",
    "                kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "                y_err = []\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                # Cross Validaiton\n",
    "                for train_index, val_index in kf.split(train_data):\n",
    "                #     print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n",
    "                    train_copy = train_data.copy()\n",
    "                    train_copy.drop(columns=[label_column])\n",
    "                    train_df = train_copy.iloc[train_index]\n",
    "                    \n",
    "                    X_val = np.matrix(train_copy.iloc[val_index].to_numpy())\n",
    "                    y_val = np.matrix(train_data.iloc[val_index][label_column].to_numpy()).T\n",
    "\n",
    "                    model = LFR(\n",
    "                        train_df,\n",
    "                        \"two_year_recid\",\n",
    "                        \"race\",\n",
    "                        1,\n",
    "                        K,\n",
    "                        Ax,\n",
    "                        Ay,\n",
    "                        Az\n",
    "                    )\n",
    "                    model.fit(init_param, maxiters=500)\n",
    "                    \n",
    "                    y_hat = model.predict(X_val)\n",
    "                #     print(y_hat)\n",
    "                    y_err.append(compute_error(y_hat, y_val))\n",
    "\n",
    "                end = time.time()\n",
    "\n",
    "                print(str(K), str(Ax), str(Ay), str(Az), \"mean val MAE:\", np.mean(y_err))\n",
    "                print(\"Time lapsed\", str((end - start)*1000))\n",
    "\n",
    "                # add to dict\n",
    "                cval_errs[model.__name__] = np.mean(y_err)\n",
    "                train_time[model.__name__] = (end - start)*1000\n",
    "                if np.mean(y_err) < best_err:\n",
    "                    best_model = model\n",
    "                    best_err = np.mean(y_err)\n",
    "                    best_errs = y_err\n",
    "                \n",
    "print(best_model.__name__, best_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85ccd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d13792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9453de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_param = np.random.uniform(size=df.shape[1] * 2 + K + df.shape[1] * K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1dab3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5 1e-08 0.01 1000'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 5\n",
    "label_column = \"two_year_recid\"\n",
    "model = LFR(\n",
    "    data_train,\n",
    "    label_column,\n",
    "    \"race\",\n",
    "    1,\n",
    "    K,\n",
    "    0.00000001,\n",
    "    0.01,\n",
    "    1000\n",
    ")\n",
    "model.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: 5 1e-08 0.01 1000 step: 850 loss: 29.551633373436616 Lx: 9565.158192355306 Ly: 1928.992428084804 Lz: 0.01026161344100665\n",
      "model: 5 1e-08 0.01 1000 step: 900 loss: 29.551633373448816 Lx: 9565.159412286783 Ly: 1928.992428084804 Lz: 0.01026161344100665\n"
     ]
    }
   ],
   "source": [
    "model.fit(init_param, maxiters=15000)\n",
    "# Predict\n",
    "test_copy = data_test.copy()\n",
    "test_copy.drop(columns=[label_column])\n",
    "\n",
    "X_test = np.matrix(test_copy.to_numpy())\n",
    "y_test = np.matrix(data_test[label_column].to_numpy()).T\n",
    "y_hat = model.predict(X_test)\n",
    "print(\"error:\", compute_error(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667a5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
