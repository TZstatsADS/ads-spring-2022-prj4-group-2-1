{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e081263",
   "metadata": {},
   "source": [
    "## Project 4 Machine Learning Fairness Algorithms Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11bfcd",
   "metadata": {},
   "source": [
    "### LFR vs DM and DM-sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234bf45",
   "metadata": {},
   "source": [
    "Information systems are becoming increasingly reliant on statistical inference and learning to render all sorts\n",
    "of decisions such as the targeting of advertising and the issuing of bank loans. With growing use of automated decision-making, problems rise. Unfairness arises around certain attributes, such as race and gender. Such attributes, some call \"sensitive attributes\", some call \"protected group\", often lead to unfair results based on attribute group. \n",
    "\n",
    "Today our group, group 2, is going to compare machine learning fairness algorithm performance that could handle sensitive attributes. \n",
    "\n",
    "Our target is LFR and DM and DM-sen, which represent Learning Fair Representation Algorithm and Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment Algorithm respectively. \n",
    "\n",
    "First let me introduce you with what each algorithm does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c39bb",
   "metadata": {},
   "source": [
    "### Learning fair representations (LFR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6948fc",
   "metadata": {},
   "source": [
    "LFR aims at achieving both group fairness (the proportion of members in a protected group receiving positive classification is identical to the proportion in the population as a whole), and individual fairness (similar individuals should be treated similarly). \n",
    "\n",
    "To achieve this, LFR formulate fairness as an optimization problem of finding a good representation of the data with two competing goals: \n",
    "\n",
    "1.encode data as well as possible\n",
    "\n",
    "2.obfuscate information about membership in the protected group.\n",
    "\n",
    "The method LFR uses is to create an intermediate representation of the original inputs that satisfy the above two goals. Then do further machine learning tasks based on this intermediate representation.\n",
    "\n",
    "LFR maps each individual, represented as a data point in a given input space, to a probability distribution in a new representation space based on the following LOSS function from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35f2c9",
   "metadata": {},
   "source": [
    "<h3 align = \"center\">$Total \\space Loss = A_z * L_z + A_x * L_x + A_y * L_y$<h3>\n",
    "\n",
    "    where\n",
    "<div align='center' ><font size='3'>$L_z= \\sum_{k=1}^K|M_k^+-M_k^-|$</font></div>\n",
    "<div align='center' ><font size='3'>$L_x = \\sum_{n=1}^N (x_n - \\hat{x}_n)^2$</font></div>\n",
    "<div align='center' ><font size='3'>$L_y = \\sum_{n=1}^N -y_n log \\hat{y}_n - (1-y_n)log(1- \\hat{y}_n)$</font></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b847448",
   "metadata": {},
   "source": [
    "A_z, A_x, A_y are hyperparameters decide trade-offs between system desired data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2968443",
   "metadata": {},
   "source": [
    "While the first two terms encourage the system to encode all information in the input attributes except for those that can lead to biased decisions, the third term requires that the prediction of y is as accurate as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2207873",
   "metadata": {},
   "source": [
    "Data is first splitted based on protected and nonprotected. After doing individual train test split based on protected and nonprotected data, concate them together to make the final training, validation and test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276d8f2",
   "metadata": {},
   "source": [
    "### Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classification without Disparate Mistreatment (DM and DM-sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb9c41",
   "metadata": {},
   "source": [
    "DM and DM-sen introduced a new notion here, Disparate Mistreatment. As we all know, in order to maximize the utility of information systems (or, classifiers), their training involves minimizing the errors (or, misclassifications) over the given historical data. But it is quite possible that the optimally trained classifier makes decisions for people belonging to different social groups with different misclassification rates. This difference in misclassification rate is Disparate Mistreatment.\n",
    "\n",
    "In order to measure disparate mistreatment, in the extent of decision boundary-based classifiers (e.g.logistic regression, SVMs), disparate mistreatment is measure using the covariance between the usersâ€™ sensitive attributes and the signed distance between the feature vectors of misclassified users and the classifier decision boundary. \n",
    "\n",
    "Then disparate mistreatment can be used in the constraints for minimizing the convex loss theta.\n",
    "\n",
    "The final optimization problem is as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643c3da",
   "metadata": {},
   "source": [
    "<h3 align = \"center\">$min\\:\\:L\\left(\\theta \\right)$<h3>\n",
    "<div align='center' ><font size='3'>$s.t.\\:\\frac{-N_1}{N}\\sum _{\\left(x,y\\right)\\in D_0}g_{\\theta }\\left(y,x\\right)+\\frac{N_0}{N}\\sum \\:_{\\left(x,y\\right)\\in \\:D_1}g_{\\theta \\:}\\left(y,x\\right)\\le c$</font></div>\n",
    "<div align='center' ><font size='3'>$\\frac{-N_1}{N}\\sum _{\\left(x,y\\right)\\in D_0}g_{\\theta }\\left(y,x\\right)+\\frac{N_0}{N}\\sum \\:_{\\left(x,y\\right)\\in \\:D_1}g_{\\theta \\:}\\left(y,x\\right)\\ge -c$</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98928448",
   "metadata": {},
   "source": [
    "Where $D_0$ and $D_1$ are the subsets of training dataset $D$ taking values $z = 0$ and $z = 1$, respectively, $N_0\\:=\\:\\left|D_0\\right|$ and $N_1\\:=\\:\\left|D_1\\right|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29917d7f",
   "metadata": {},
   "source": [
    "### Model Performance and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1854d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c874d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run LFR.ipynb\n",
    "%run ../lib/DM_DM_sen_Model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7df14",
   "metadata": {},
   "source": [
    "#### LFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa850070",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat_priv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17092/3194276597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"priv error:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat_priv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y_plus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"non priv error:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat_nonpriv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y_minus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m print(\"overall error:\", compute_error(np.concatenate((y_hat_nonpriv, y_hat_priv)), \n\u001b[0;32m      4\u001b[0m                                       np.concatenate((test_y_minus, test_y_plus))))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_hat_priv' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"priv error:\", compute_error(y_hat_priv, test_y_plus))\n",
    "print(\"non priv error:\", compute_error(y_hat_nonpriv, test_y_minus))\n",
    "print(\"overall error:\", compute_error(np.concatenate((y_hat_nonpriv, y_hat_priv)), \n",
    "                                      np.concatenate((test_y_minus, test_y_plus))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9259b",
   "metadata": {},
   "source": [
    "#### DM Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bcf9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Unconstrained (original) classifier ==\n",
      "{'cons_type': 0, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.660\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.34 || 0.32 ||\n",
      "||  1  || 0.18 || 0.62 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "{'cons_type': 1, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.649\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.27 || 0.41 ||\n",
      "||  1  || 0.25 || 0.53 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "{'cons_type': 2, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.651\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.28 || 0.39 ||\n",
      "||  1  || 0.29 || 0.47 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR and FPR ==\n",
      "{'cons_type': 4, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.651\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.27 || 0.41 ||\n",
      "||  1  || 0.24 || 0.53 ||\n",
      "\n",
      "\n",
      "runtime of the complete DM model is 6.82 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "loss_function = \"logreg\" \n",
    "EPS = 1e-6\n",
    "cons_type = 0 # No constraint at very beginning \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "\n",
    "cons_params = None\n",
    "cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "start_dm = time.time()\n",
    "return_accuracy_noConstraint()\n",
    "return_accuracy_FPR()\n",
    "return_accuracy_FNR()\n",
    "return_accuracy_allConstraints()\n",
    "\n",
    "end_dm = time.time()\n",
    "runtime_dm = (end_dm-start_dm)\n",
    "print(f'runtime of the complete DM model is {np.round(runtime_dm, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0a951",
   "metadata": {},
   "source": [
    "#### DM Support vector machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d7c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Unconstrained (original) classifier ==\n",
      "{'cons_type': 0, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.649\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.30 ||\n",
      "||  1  || 0.20 || 0.62 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "{'cons_type': 1, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.650\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.31 || 0.37 ||\n",
      "||  1  || 0.27 || 0.51 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "{'cons_type': 2, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.652\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.35 ||\n",
      "||  1  || 0.27 || 0.50 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR and FPR ==\n",
      "{'cons_type': 4, 'tau': 5.0, 'mu': 1.2, 'sensitive_attrs_to_cov_thresh': {'race': {0: {0: 0, 1: 0}, 1: {0: 0, 1: 0}, 2: {0: 0, 1: 0}}}}\n",
      "\n",
      "\n",
      "Accuracy: 0.650\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.28 || 0.40 ||\n",
      "||  1  || 0.24 || 0.53 ||\n",
      "\n",
      "\n",
      "runtime of the complete DM model is 4.22 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "loss_function = \"svm\" \n",
    "EPS = 1e-6\n",
    "cons_type = 0 # No constraint at very beginning \n",
    "tau = 5.0\n",
    "mu = 1.2\n",
    "sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "\n",
    "cons_params = None\n",
    "cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "start_dm = time.time()\n",
    "return_accuracy_noConstraint()\n",
    "return_accuracy_FPR()\n",
    "return_accuracy_FNR()\n",
    "return_accuracy_allConstraints()\n",
    "\n",
    "end_dm = time.time()\n",
    "runtime_dm = (end_dm-start_dm)\n",
    "print(f'runtime of the complete DM model is {np.round(runtime_dm, 2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff1fee",
   "metadata": {},
   "source": [
    "### Result Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57fd30",
   "metadata": {},
   "source": [
    "As we see, the accuracy for the LFR model is XX% and the accuracy of the DM and DM-sen model is XX%. There is an apparent decrease in accuracy from DM and DM-sen model to LFR model. This makes sense because fairness measure \"cleans\" the data to achieve fairness while DM and DM-sen does not remove information from the data.\n",
    "\n",
    "But there could also be other explainations. There could be sampling bias. There might also be label bias where some mis-labeled entities fall into a sensitive group. Or maybe the ground truth(target) itself is just unfair, fairness measure might just harm model accuracy. There are more factors to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790a29e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utils\n",
      "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab71c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
